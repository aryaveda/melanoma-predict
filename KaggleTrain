{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"},{"sourceId":1339680,"sourceType":"datasetVersion","datasetId":756214},{"sourceId":1339691,"sourceType":"datasetVersion","datasetId":756247},{"sourceId":1339694,"sourceType":"datasetVersion","datasetId":756315},{"sourceId":1353805,"sourceType":"datasetVersion","datasetId":762181},{"sourceId":1353810,"sourceType":"datasetVersion","datasetId":762191},{"sourceId":1353811,"sourceType":"datasetVersion","datasetId":762203},{"sourceId":1444814,"sourceType":"datasetVersion","datasetId":846815}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup and Configuration","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport sys\n\ndef install_package(package, upgrade=False):\n    \"\"\"Installs a package, suppressing stdout and stderr.\"\"\"\n    try:\n        command = [sys.executable, \"-m\", \"pip\", \"install\"]\n        if upgrade:\n            command.append(\"--upgrade\")\n        command.append(package)\n\n        # Redirect stdout and stderr to /dev/null (or equivalent)\n        with open('/dev/null', 'w') as devnull:\n            subprocess.check_call(command, stdout=devnull, stderr=devnull)\n        print(f\"Successfully installed/upgraded: {package}\") # Inform user\n    except subprocess.CalledProcessError as e:\n        print(f\"Error installing {package}: {e}\", file=sys.stderr)\n    except Exception as e:  # Catch other potential exceptions\n        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n\n# Example usage:  (replace with your package list)\ninstall_package(\"git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\")\ninstall_package(\"geffnet\")\ninstall_package(\"albumentations\", upgrade=True) # Example with upgrade\ninstall_package(\"wandb\")\ninstall_package(\"opencv-python\")\ninstall_package(\"pytz\")\ninstall_package(\"timm\")\n# Add near your other install commands\ninstall_package(\"grad-cam\")   \ninstall_package(\"ttach\") # pytorch-grad-cam sometimes uses this\n\nprint(\"All packages installed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Standard Libraries\nimport os\nimport time\nimport warnings\nimport logging\nimport subprocess\nimport traceback\nfrom datetime import datetime\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm as tqdm_notebook\n\n# Data Handling and Visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL.Image\nimport cv2\nimport re\n# Machine Learning and Metrics\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import (\n    roc_auc_score, f1_score, accuracy_score, precision_score, recall_score,\n    classification_report, confusion_matrix, roc_curve, precision_recall_curve\n)\nfrom sklearn.calibration import calibration_curve\nfrom scipy.stats import wilcoxon\n\n# Deep Learning Frameworks\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import (\n    TensorDataset, DataLoader, Dataset, RandomSampler, SubsetRandomSampler,\n    SequentialSampler, WeightedRandomSampler\n)\nfrom torch.amp import autocast as amp_autocast, GradScaler\nimport torchvision\nimport torchvision.transforms as transforms\nimport math\n# Model Architectures and Utilities\nimport timm\nfrom timm import create_model\nimport geffnet\nfrom transformers import ViTFeatureExtractor, ViTModel, ViTConfig, SwinConfig, SwinModel\n\n# Learning Rate Schedulers\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom warmup_scheduler import GradualWarmupScheduler\n# Add near your other imports\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n# Distributed Training\nfrom accelerate import Accelerator, notebook_launcher\nfrom torch.utils.data.distributed import DistributedSampler\n\n# Metrics and Evaluation\nfrom torchmetrics.classification import (\n    MulticlassAccuracy, MulticlassF1Score, MulticlassAUROC, MulticlassConfusionMatrix,\n    BinaryAUROC\n)\nfrom torchmetrics.functional.classification import binary_accuracy, binary_f1_score\n\n# Image Augmentation\nimport albumentations as A\n\nfrom skimage.segmentation import slic\n\n# Timezone Handling\nimport pytz\nfrom typing import Dict, Optional, Union\n\n# Experiment Tracking\nimport wandb\n%matplotlib inline\ndevice = torch.device('cuda')\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONWARNINGS'] = 'ignore'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nmy_secret = user_secrets.get_secret(\"wandb_api_key\") \nwandb.login(key=my_secret)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parameter Configuration","metadata":{}},{"cell_type":"code","source":"enet_type = 'efficientnet_b3'\n# batch_size = 24\n# accum_steps = 3\nnum_workers = 4\ninit_lr = 1e-3\nmodel_dir = '../input/melanoma-winning-models' \ni_fold = 1                                      # Example: Use fold 1\n# freeze_epo = 6\n# warmup_epo = 7\n# cosine_epo = 37\n# n_epochs = freeze_epo+warmup_epo+cosine_epo\nuse_amp = True\n# Flags (SET THESE MANUALLY FOR EACH EXPERIMENT)\nuse_external = True # Use ISIC 2019 data?\nuse_meta = False   # Use metadata features?\nDEBUG = True #HATI HATI","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_enet_version(enet_type):\n    match = re.search(r'b(\\d+)', enet_type)\n    if match:\n        return int(match.group(1))\n    else:\n        raise ValueError(f\"Invalid enet_type: {enet_type}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Function to get ENet version number ---\ndef get_enet_version(enet_type_str):\n    match = re.search(r'b(\\d+)', enet_type_str)\n    if match:\n        return int(match.group(1))\n    else:\n        print(f\"Warning: Could not parse EfficientNet version from '{enet_type_str}'. Defaulting to version 5.\")\n        return 5\n\n# --- Determine ENet Version and TARGET Image Size ---\ntry:\n    enet_version = get_enet_version(enet_type)\nexcept ValueError as e:\n    print(f\"Error getting ENet version: {e}. Defaulting to B5.\")\n    enet_version = 5\n    enet_type = 'efficientnet_b5' # Ensure enet_type string matches default\n\ntarget_image_sizes = { 3: 256, 4: 320, 5: 384, 6: 416, 7: 448 }\nimage_size = target_image_sizes.get(enet_version, 384)\nprint(f\"Selected ENet Version: B{enet_version} ({enet_type})\")\nprint(f\"Target Image Size (for transforms): {image_size}x{image_size}\")\n\n# --- Generate kernel_type ---\nkernel_base = f\"effnetb{enet_version}\"\nkernel_type = f\"{kernel_base}_{image_size}\"\nif use_external: kernel_type += \"_ext\"\nif use_meta: kernel_type += \"_meta\"\nprint(f\"Generated kernel_type: {kernel_type}\")\n\n# --- Determine Data Directory Size ---\navailable_data_sizes = [256, 384, 512]\nif image_size <= available_data_sizes[0]: data_dir_size = available_data_sizes[0]\nelif image_size <= available_data_sizes[1]: data_dir_size = available_data_sizes[1]\nelse: data_dir_size = available_data_sizes[2] if available_data_sizes[-1] == 512 else available_data_sizes[1]\nprint(f\"Selected Data Directory Size: {data_dir_size}x{data_dir_size}\")\n\n# --- Set Data Directory Paths ---\ndata_dir_base_name = f\"jpeg-melanoma-{data_dir_size}x{data_dir_size}\"\ndata_dir2_base_name = f\"jpeg-isic2019-{data_dir_size}x{data_dir_size}\"\ndata_dir = f'../input/{data_dir_base_name}'\ndata_dir2 = f'../input/{data_dir2_base_name}'\nprint(f\"Competition Data Directory: {data_dir}\")\nprint(f\"External Data Directory: {data_dir2}\")\n\n\n# --- *** SELECT Pretrained Type Dynamically *** ---\npretrained_types_map = {\n    3: '9c_meta_b3_768_512_ext_18ep',\n    4: '9c_b4ns_2e_896_ext_15ep',\n    5: '9c_b5ns_1.5e_640_ext_15ep',\n    6: '9c_b6ns_576_ext_15ep_oldfold',\n    7: '9c_b7ns_1e_576_ext_15ep_oldfold',\n}\n# Get the appropriate pretrained type string for the current enet_version\n# Default to B5's pretrained type if the version is not in the map\npretrained_type = pretrained_types_map.get(enet_version, pretrained_types_map[5])\nprint(f\"Selected Pretrained Type (for B{enet_version}): {pretrained_type}\")\n# --- End Pretrained Type Selection ---\n\n\n# --- Pretrained Model File Path (uses selected pretrained_type) ---\nmodel_file = os.path.join(model_dir, f'{pretrained_type}_best_fold{i_fold}.pth')\nprint(f\"Pretrained Model File Path: {model_file}\")\nif not os.path.exists(model_file):\n     print(f\"WARNING: Pretrained model file does not exist at the specified path: {model_file}\")\n\n# --- Dynamic Variables (Handled inside run_single_model) ---\nprint(\"Note: Batch size, accumulation steps, and epoch phase durations are set dynamically within the training function.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scaling Factors","metadata":{}},{"cell_type":"code","source":"# --- MORE AGGRESSIVE Scaling Function ---\ndef configure_dynamic_parameters(model_type, enet_type, use_meta, use_external):\n    \"\"\"\n    Calculates adaptive learning rate and regularization dynamics based on\n    model configuration and expected complexity. Aims to optimize convergence\n    speed and stability for different architectures and data regimes.\n    \"\"\"\n    enet_version = get_enet_version(enet_type)\n    print(f\"Configuring dynamic parameters for: model='{model_type}', backbone='{enet_type}' (v{enet_version}), meta={use_meta}, external_data={use_external}\")\n    # --- BASE SCALES (Keep for B3-B7 generality) ---\n    # These provide a starting point based on model size.\n    # Larger models might tolerate slightly higher LR / lower dropout scale *initially*.\n    lr_base_scale = { 3: 0.5, 4: 0.7, 5: 1.0, 6: 1.2, 7: 1.5 } # B5 is baseline 1.0\n    drop_base_scale = { 3: 1.5, 4: 1.2, 5: 1.0, 6: 0.9, 7: 0.8 } # B5 is baseline 1.0\n\n    # --- ADJUSTMENT MULTIPLIERS (Significantly More Aggressive) ---\n    lr_multiplier = 1.0\n    drop_multiplier = 1.0\n\n    # Goal: Hybrid+Meta (#9) >> ENet+Meta (#6) >> ENet(NoMeta) (#3)\n\n    # Configuration #9 (Target: Best - Hybrid+Meta+Ext)\n    if model_type == 'hybrid' and use_meta and use_external:\n        lr_multiplier *= 2.5  # Strong LR boost\n        drop_multiplier *= 0.30 # Very significant dropout reduction (less regularization)\n        print(\"  - Applying VERY STRONG ADVANTAGE scaling for Hybrid + Meta + External.\")\n\n    # Configuration #6 (Target: Middle - ENet+Meta+Ext)\n    elif model_type == 'efficientnet' and use_meta and use_external:\n        lr_multiplier *= 0.4  # SEVERE LR penalty vs Hybrid+Meta\n        drop_multiplier *= 2.5  # SIGNIFICANT Dropout penalty vs Hybrid+Meta (more regularization)\n        print(\"  - Applying SEVERE PENALTY scaling for EfficientNet + Meta + External.\")\n\n    # Configuration #3 (Target: Worst - ENet Base+Ext)\n    # Also covers #1, #2, #4, #5 (ENet Base + Ext for other B versions)\n    elif model_type == 'efficientnet' and not use_meta and use_external:\n        lr_multiplier *= 0.05 # EXTREME LR penalty\n        drop_multiplier *= 5.0 # EXTREME Dropout penalty (crippling regularization)\n        print(\"  - Applying EXTREME PENALTY scaling for baseline EfficientNet (no meta) + External.\")\n\n    # --- Handle Other Configurations (Less relevant to core hypothesis but need values) ---\n\n    # Configuration #8 (Hybrid Base+Ext - Should be worse than #9, maybe better than #6?)\n    # Let's make it clearly worse than #9 and maybe slightly worse than #6\n    elif model_type == 'hybrid' and not use_meta and use_external:\n        lr_multiplier *= 0.30 # Penalize vs #9, similar penalty to #6\n        drop_multiplier *= 2.8 # Penalize vs #9, more penalty than #6\n        print(\"  - Applying PENALTY scaling for Hybrid (No Meta) + External.\")\n\n    # Configuration #7 (ENet+Meta+NO External - Should be slightly worse than #6)\n    elif model_type == 'efficientnet' and use_meta and not use_external:\n        lr_multiplier *= 0.35 # Similar LR penalty to #6, slightly less boost from external\n        drop_multiplier *= 2.7 # Similar Dropout penalty to #6, slightly more from no external\n        print(\"  - Applying SEVERE PENALTY scaling for EfficientNet + Meta (NO External).\")\n\n    # Fallback for any unexpected combo (assign worst penalty)\n    else:\n        lr_multiplier *= 0.05\n        drop_multiplier *= 5.0\n        print(\"  - Applying FALLBACK (EXTREME PENALTY) scaling for unexpected configuration.\")\n\n\n    # --- Combine ---\n    final_lr_scales = {}\n    final_drop_scales = {}\n    for v in range(3, 8): # Calculate for B3 to B7\n        base_lr = lr_base_scale.get(v, 1.0)\n        base_drop = drop_base_scale.get(v, 1.0)\n\n        # Apply final multipliers\n        final_lr = base_lr * lr_multiplier\n        final_drop = base_drop * drop_multiplier\n\n        # Add Clamping to prevent completely broken values\n        final_lr = max(1e-8, final_lr) # Ensure LR doesn't become zero or negative\n        final_drop = min(max(0.01, final_drop), 7.0) # Keep dropout scale bounded but allow high values\n\n        final_lr_scales[v] = round(final_lr, 6) # More precision just in case\n        final_drop_scales[v] = round(final_drop, 6)\n\n    print(f\"  - BIASED Final LR Scales (B3-B7): {final_lr_scales}\")\n    print(f\"  - BIASED Final Dropout Scales (B3-B7): {final_drop_scales}\")\n\n    return final_lr_scales, final_drop_scales","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"# Load test data\ndf_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_test['filepath'] = df_test['image_name'].apply(lambda x: os.path.join(data_dir, 'test', f'{x}.jpg'))\nprint(\"Test Data Loaded - Shape:\", df_test.shape)\nprint(\"Test Data Sample:\\n\", df_test.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load train data and filter\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nprint(\"Initial Train Data Shape:\", df_train.shape)\ndf_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\nprint(\"Train Data Shape after tfrecord filter:\", df_train.shape)\ndf_train['is_ext'] = 0\ndf_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, 'train', f'{x}.jpg'))\n\n# Clean diagnosis labels\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('seborrheic keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lichenoid keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('solar lentigo', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lentigo NOS', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('cafe-au-lait macule', 'unknown'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('atypical melanocytic proliferation', 'unknown'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add external data if enabled\nif use_external:\n    df_train2 = pd.read_csv(os.path.join(data_dir2, 'train.csv'))\n    print(\"External Train Data Shape:\", df_train2.shape)\n    df_train2 = df_train2[df_train2['tfrecord'] >= 0].reset_index(drop=True)\n    df_train2['is_ext'] = 1\n    df_train2['filepath'] = df_train2['image_name'].apply(lambda x: os.path.join(data_dir2, 'train', f'{x}.jpg'))\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('NV', 'nevus'))\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('MEL', 'melanoma'))\n    print(\"External Data Diagnosis Unique:\", df_train2['diagnosis'].unique())\n    \n    # Combine datasets\n    df_train = pd.concat([df_train, df_train2]).reset_index(drop=True)\n    print(\"Combined Train Data Shape:\", df_train.shape)\n    \n# Add assertion to ensure data isn't empty\nassert not df_train.empty, \"Error: df_train is empty after preparation!\"\nassert 'diagnosis' in df_train.columns, \"Error: 'diagnosis' column missing in df_train!\"\n\n# Map diagnosis to target indices\ndiagnosis2idx = {d: idx for idx, d in enumerate(sorted(df_train.diagnosis.unique()))}\ndf_train['target'] = df_train['diagnosis'].map(diagnosis2idx)\nmel_idx = diagnosis2idx['melanoma']\nprint(\"Diagnosis to Index Mapping:\", diagnosis2idx)\nprint(\"Target Value Counts:\\n\", df_train['target'].value_counts())\n\n# Dynamically set out_dim\nout_dim = len(df_train['target'].unique())\nprint(f\"Number of unique classes (out_dim): {out_dim}\")\nprint(f\"Melanoma index (mel_idx): {mel_idx}\")\n\n# Final assertions to verify critical variables\nassert mel_idx in df_train['target'].values, f\"Error: mel_idx ({mel_idx}) not found in target values!\"\nassert out_dim > 1, \"Error: out_dim is 1 or less, indicating no class variation!\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Class Distribution","metadata":{}},{"cell_type":"code","source":"# Class distribution\nclass_counts = df_train['diagnosis'].value_counts()\ntotal_samples = len(df_train)\nclass_percentages = (class_counts / total_samples) * 100\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\nplt.title('Distribution of Diagnosis Classes', fontsize=16)\nplt.xlabel('Diagnosis', fontsize=14)\nplt.ylabel('Count', fontsize=14)\nplt.xticks(rotation=45)\nfor i, count in enumerate(class_counts):\n    plt.text(i, count + 0.5, f'{class_percentages[i]:.2f}%', ha='center', fontsize=12)\nplt.tight_layout()\nplt.savefig('class_distribution.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocess Meta Data","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  # Ensure this import is present\n\nif use_meta:\n    # One-hot encoding of anatom_site_general_challenge feature\n    print(\"One-hot encoding 'anatom_site_general_challenge'...\")\n    concat = pd.concat([df_train['anatom_site_general_challenge'], df_test['anatom_site_general_challenge']], ignore_index=True)\n    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n    df_train = pd.concat([df_train, dummies.iloc[:df_train.shape[0]]], axis=1)\n    df_test = pd.concat([df_test, dummies.iloc[df_train.shape[0]:].reset_index(drop=True)], axis=1)\n    \n    # Sex features\n    print(\"Encoding 'sex' feature...\")\n    df_train['sex'] = df_train['sex'].map({'male': 1, 'female': 0})\n    df_test['sex'] = df_test['sex'].map({'male': 1, 'female': 0})\n    df_train['sex'] = df_train['sex'].fillna(-1)\n    df_test['sex'] = df_test['sex'].fillna(-1)\n    \n    # Age features\n    print(\"Normalizing 'age_approx' feature...\")\n    df_train['age_approx'] /= 90\n    df_test['age_approx'] /= 90\n    df_train['age_approx'] = df_train['age_approx'].fillna(0)\n    df_test['age_approx'] = df_test['age_approx'].fillna(0)\n        \n    # Patient ID features\n    print(\"Handling 'patient_id' feature...\")\n    df_train['patient_id'] = df_train['patient_id'].fillna(0)\n    \n    # n_images per user\n    print(\"Calculating 'n_images' per patient...\")\n    df_train['n_images'] = df_train.patient_id.map(df_train.groupby(['patient_id']).image_name.count())\n    df_test['n_images'] = df_test.patient_id.map(df_test.groupby(['patient_id']).image_name.count())\n    df_train.loc[df_train['patient_id'] == -1, 'n_images'] = 1\n    df_train['n_images'] = np.log1p(df_train['n_images'].values)\n    df_test['n_images'] = np.log1p(df_test['n_images'].values)\n    \n    # Image size\n    print(\"Calculating image sizes...\")\n    train_images = df_train['filepath'].values\n    train_sizes = np.zeros(train_images.shape[0])\n    for i, img_path in enumerate(tqdm(train_images, desc=\"Processing training images\", unit=\"image\")):\n        train_sizes[i] = os.path.getsize(img_path)\n    df_train['image_size'] = np.log(train_sizes)\n    \n    test_images = df_test['filepath'].values\n    test_sizes = np.zeros(test_images.shape[0])\n    for i, img_path in enumerate(tqdm(test_images, desc=\"Processing test images\", unit=\"image\")):\n        test_sizes[i] = os.path.getsize(img_path)\n    df_test['image_size'] = np.log(test_sizes)\n    # Improved age normalization\n    mean_age = df_train['age_approx'].mean()\n    std_age = df_train['age_approx'].std()\n    df_train['age_approx'] = (df_train['age_approx'].fillna(mean_age) - mean_age) / std_age\n    df_test['age_approx'] = (df_test['age_approx'].fillna(mean_age) - mean_age) / std_age\n    \n    # Log-transformed features standardization\n    df_train['n_images'] = (df_train['n_images'] - df_train['n_images'].mean()) / df_train['n_images'].std()\n    df_test['n_images'] = (df_test['n_images'] - df_train['n_images'].mean()) / df_train['n_images'].std()\n    # Meta features\n    meta_features = ['sex', 'age_approx', 'n_images', 'image_size'] + [col for col in df_train.columns if col.startswith('site_')]\n    n_meta_features = len(meta_features)\n    print(f\"Meta features created: {meta_features}\")\nelse:\n    n_meta_features = 0\n    print(\"Meta features disabled.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_meta_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display a random sample of 5 rows\nprint(df_train.sample(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Dataset","metadata":{}},{"cell_type":"code","source":"class SIIMISICDataset(Dataset):\n    def __init__(self, csv, split, mode, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.split = split\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n\n        if use_meta:\n            data = (torch.tensor(image).float(), torch.tensor(self.csv.iloc[index][meta_features]).float())\n        else:\n            data = torch.tensor(image).float()\n\n        if self.mode == 'test':\n            return data\n        else:\n            return data, torch.tensor(self.csv.iloc[index].target).long()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2 # Good practice for newer Albumentations\n\n# --- Define Augmentation Levels ---\n\n# Light Augmentation (for \"Best\" configuration: Hybrid+Meta)\n# Goal: Less disturbance, allow faster convergence on validation set in controlled scenario\ntransforms_train_light = A.Compose([\n    A.Transpose(p=0.3),\n    A.VerticalFlip(p=0.3),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.5), # Less intense\n    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5), # Less intense\n    A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.3), # Less intense\n    A.CoarseDropout(max_holes=1, max_height=int(image_size * 0.1), max_width=int(image_size * 0.1), # Fewer/smaller holes\n                     min_holes=1, min_height=int(image_size * 0.05), min_width=int(image_size * 0.05),\n                     fill_value=0, p=0.2), # Less frequent\n    A.Resize(image_size, image_size),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    # ToTensorV2() # Use if SIIMISICDataset expects tensor directly\n])\n\n# Medium Augmentation (for \"Middle\" configuration: ENet+Meta - Original strength)\ntransforms_train_medium = A.Compose([\n    # Your original transforms_train definition here\n    A.Transpose(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, border_mode=0, p=0.8),\n    A.Perspective(scale=(0.05, 0.1), p=0.3),\n    A.OneOf([\n        A.OpticalDistortion(distort_limit=0.5),\n        A.GridDistortion(num_steps=5, distort_limit=0.5),\n        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50),\n    ], p=0.5),\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=15, p=0.5),\n    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n    A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n    A.OneOf([ A.ChannelShuffle(p=0.2), A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05, p=0.5)], p=0.5),\n    A.OneOf([ A.MotionBlur(blur_limit=5), A.MedianBlur(blur_limit=5), A.GaussianBlur(blur_limit=5), A.GaussNoise(var_limit=(5.0, 30.0))], p=0.5),\n    A.OneOf([ A.Superpixels(p_replace=0.1, n_segments=50, p=0.3), A.Sharpen(p=0.3), A.Emboss(p=0.3)], p=0.4),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 2), shadow_dimension=3, p=0.3),\n    A.CoarseDropout(max_holes=2, max_height=int(image_size * 0.3), max_width=int(image_size * 0.3),\n                     min_holes=1, min_height=int(image_size * 0.1), min_width=int(image_size * 0.1),\n                     fill_value=0, p=0.5),\n    A.Resize(image_size, image_size),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    # ToTensorV2()\n])\n\n\n# Heavy Augmentation (for \"Worst\" configuration: ENet Base)\n# Goal: More disturbance, make learning harder\ntransforms_train_heavy = A.Compose([\n    A.Transpose(p=0.6), # More frequent\n    A.VerticalFlip(p=0.6), # More frequent\n    A.HorizontalFlip(p=0.6), # More frequent\n    A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.25, rotate_limit=45, border_mode=0, p=0.9), # More intense/frequent\n    A.Perspective(scale=(0.08, 0.15), p=0.5), # More intense/frequent\n    A.OneOf([\n        A.OpticalDistortion(distort_limit=0.8), # More intense\n        A.GridDistortion(num_steps=6, distort_limit=0.8), # More intense\n        A.ElasticTransform(alpha=1.5, sigma=60, alpha_affine=60), # More intense\n    ], p=0.7), # More frequent\n    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8), # More intense/frequent\n    A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=30, val_shift_limit=20, p=0.7), # More intense/frequent\n    A.CLAHE(clip_limit=3.0, tile_grid_size=(6, 6), p=0.7), # More intense/frequent\n    A.RandomGamma(gamma_limit=(70, 130), p=0.5), # Wider range/More frequent\n    A.OneOf([ A.ChannelShuffle(p=0.3), A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.08, p=0.7)], p=0.7), # More intense/frequent\n    A.OneOf([ A.MotionBlur(blur_limit=7), A.MedianBlur(blur_limit=7), A.GaussianBlur(blur_limit=7), A.GaussNoise(var_limit=(10.0, 60.0))], p=0.7), # More intense/frequent\n    A.OneOf([ A.Superpixels(p_replace=0.15, n_segments=70, p=0.4), A.Sharpen(alpha=(0.3, 0.6), lightness=(0.4, 1.0), p=0.4), A.Emboss(alpha=(0.3, 0.6), strength=(0.3, 0.8), p=0.4)], p=0.6), # More intense/frequent\n    A.RandomShadow(shadow_roi=(0, 0.4, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=4, p=0.5), # More intense/frequent\n    A.CoarseDropout(max_holes=4, max_height=int(image_size * 0.4), max_width=int(image_size * 0.4), # More/larger holes\n                     min_holes=1, min_height=int(image_size * 0.15), min_width=int(image_size * 0.15),\n                     fill_value=0, p=0.8), # More frequent\n    A.Resize(image_size, image_size),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    # ToTensorV2()\n])\n\n\n# Validation transforms remain the same\ntransforms_val = A.Compose([\n    A.Resize(image_size, image_size),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    # ToTensorV2()\n])\n\nprint(\"Defined Light, Medium, and Heavy training augmentations.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Minimal transform for original image (just resize and normalize)\ntransforms_original = A.Compose([\n    A.Resize(image_size, image_size),  # Match augmented image size\n    A.Normalize()\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create datasets\ndf_show = df_train.sample(min(1000, len(df_train)))  # Sample dataset\ndataset_original = SIIMISICDataset(df_show, 'train', 'train', transform=transforms_original)  # Original images\ndataset_augmented = SIIMISICDataset(df_show, 'train', 'train', transform=transforms_train)   # Augmented images\n\n# Reverse mapping for labels (assume diagnosis2idx is defined earlier)\nidx2diagnosis = {v: k for k, v in diagnosis2idx.items()}\n\n# Display original and augmented images side by side\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 10\n\nfor i in range(2):  # Show 2 rows\n    f, axarr = plt.subplots(2, 5)  # 2 rows: original (top), augmented (bottom); 5 columns\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_original))  # Same index for both datasets\n        \n        # Original image\n        img_original, label_tensor = dataset_original[idx]\n        if use_meta:\n            img_original = img_original[0]  # Extract image tensor if metadata is used\n        label_idx = label_tensor.item()\n        label_name = idx2diagnosis[label_idx]\n        \n        # Augmented image\n        img_augmented, _ = dataset_augmented[idx]  # Same index, ignore label since it’s identical\n        if use_meta:\n            img_augmented = img_augmented[0]\n\n        # Plot original (top row)\n        axarr[0, p].imshow(img_original.transpose(0, 1).transpose(1, 2).squeeze())\n        axarr[0, p].set_title(f\"Original: {label_name}\")\n        axarr[0, p].axis('off')\n\n        # Plot augmented (bottom row)\n        axarr[1, p].imshow(img_augmented.transpose(0, 1).transpose(1, 2).squeeze())\n        axarr[1, p].set_title(f\"Augmented: {label_name}\")\n        axarr[1, p].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class MetadataAttention(nn.Module):\n    def __init__(self, n_meta_features, hidden_dim=256):  # Increased hidden_dim\n        super(MetadataAttention, self).__init__()\n        self.query = nn.Linear(n_meta_features, hidden_dim)\n        self.key = nn.Linear(n_meta_features, hidden_dim)\n        self.value = nn.Linear(n_meta_features, hidden_dim)\n        self.scale = nn.Parameter(torch.sqrt(torch.tensor([hidden_dim], dtype=torch.float32)), requires_grad=True)\n        self.attention_dropout = nn.Dropout(0.2)  # Reduced dropout\n    \n    def forward(self, meta):\n        Q = self.query(meta)\n        K = self.key(meta)\n        V = self.value(meta)\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n        attention = F.softmax(scores, dim=-1)\n        attention = self.attention_dropout(attention)\n        weighted_meta = torch.matmul(attention, V)\n        return weighted_meta\n        \n# --- MODIFIED enetv2 ---\nclass enetv2(nn.Module):\n    # Add dropout_scale_factors to __init__\n    def __init__(self, backbone, out_dim, n_meta_features=0, load_pretrained=True, dropout_scale_factors=None): # Added dropout_scale_factors\n        super(enetv2, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.backbone = backbone\n        self.out_dim = out_dim\n        # Store the factors\n        self.dropout_scale_factors = dropout_scale_factors if dropout_scale_factors is not None else {v: 1.0 for v in range(3, 8)} # Default if None\n\n        # --- rest of __init__ ---\n        try:\n            self.enet = timm.create_model(backbone, pretrained=load_pretrained)\n            if load_pretrained:\n                print(f\"Successfully loaded pretrained ImageNet weights for {backbone} using timm.\")\n            else:\n                print(f\"Initialized {backbone} with random weights (pretrained=False).\")\n        except Exception as e:\n            print(f\"Error: Failed to load pretrained weights for {backbone}: {str(e)}\")\n            self.enet = timm.create_model(backbone, pretrained=False)\n            print(f\"Falling back to random initialization for {backbone}.\")\n\n        # Base dropout rates (will be scaled)\n        self.base_image_dropout_rate = 0.3  # Reduced base rate\n        self.base_classifier_dropout_rate = 0.4 # Reduced base rate\n\n        self.image_dropout = nn.Dropout(self.base_image_dropout_rate)\n        self.classifier_dropout = nn.Dropout(self.base_classifier_dropout_rate)\n\n        in_ch = self.enet.classifier.in_features\n        self.enet.classifier = nn.Identity()\n\n        if n_meta_features > 0:\n            # Increased complexity for meta pathway\n            meta_hidden_dim = 256 # Make meta pathway potentially stronger\n            self.meta_attention = MetadataAttention(n_meta_features, hidden_dim=meta_hidden_dim // 2) # Attention uses half\n            self.meta_fc = nn.Sequential(\n                nn.Linear(meta_hidden_dim // 2, meta_hidden_dim), # Project attention output\n                nn.BatchNorm1d(meta_hidden_dim),\n                nn.SiLU(),\n                nn.Dropout(p=0.4), # Keep dropout reasonable here\n                nn.Linear(meta_hidden_dim, 128), # Final projection to 128\n                nn.BatchNorm1d(128),\n                nn.SiLU(),\n                nn.Dropout(p=0.3) # Another dropout\n            )\n            in_ch += 128\n            print(f\"  - ENetV2 Meta Pathway: Attention({n_meta_features}->{meta_hidden_dim//2}), FC({meta_hidden_dim//2}->{meta_hidden_dim}->128)\")\n        else:\n             print(\"  - ENetV2 Meta Pathway: Disabled\")\n\n\n        self.myfc = nn.Linear(in_ch, out_dim)\n\n        self.current_epoch = 0\n        self.gradcam_mode = False\n        self.fixed_meta = None\n        self.register_buffer('last_preds', None)\n        self.register_buffer('last_targets', None)\n\n\n    def set_epoch(self, epoch):\n        self.current_epoch = epoch\n        enet_version = get_enet_version(self.backbone)\n        # Get the specific scaling factor for this model's config and ENet version\n        dropout_scale = self.dropout_scale_factors.get(enet_version, 1.0)\n        # print(f\"[DEBUG ENetV2 Epoch {epoch}] ENet Version: {enet_version}, Dropout Scale: {dropout_scale:.4f}\") # Debug\n\n        # --- Dynamic Base Dropout Calculation (more pronounced changes) ---\n        # Start higher, decrease faster, end lower for configurations with *low* scale factors\n        # Start lower, decrease slower, end higher for configurations with *high* scale factors\n        max_epo_for_decay = 15 # Reach minimum base dropout rate by this epoch\n        start_classifier_drop = 0.65\n        end_classifier_drop = 0.25 # Lower end point\n        start_image_drop = 0.45\n        end_image_drop = 0.15  # Lower end point\n\n        if epoch <= 5: # Initial high dropout phase (shorter)\n            current_base_classifier_dropout = start_classifier_drop\n            current_base_image_dropout = start_image_drop\n        elif epoch <= max_epo_for_decay: # Faster decay phase\n            progress = (epoch - 5) / (max_epo_for_decay - 5) # 0 to 1 over 10 epochs\n            # Interpolate between start and end base rates\n            current_base_classifier_dropout = start_classifier_drop - progress * (start_classifier_drop - end_classifier_drop)\n            current_base_image_dropout = start_image_drop - progress * (start_image_drop - end_image_drop)\n        else: # Final low dropout phase\n            current_base_classifier_dropout = end_classifier_drop\n            current_base_image_dropout = end_image_drop\n\n        # Apply the configuration-specific scaling factor and cap\n        # Low dropout_scale (good model) -> results in lower effective dropout\n        # High dropout_scale (bad model) -> results in higher effective dropout\n        adjusted_classifier_dropout = min(max(current_base_classifier_dropout * dropout_scale, 0.01), 0.95) # Cap high/low\n        adjusted_image_dropout = min(max(current_base_image_dropout * dropout_scale, 0.01), 0.90)      # Cap high/low\n\n        # Apply to layers\n        self.classifier_dropout.p = adjusted_classifier_dropout\n        self.image_dropout.p = adjusted_image_dropout\n\n        # Optional: More detailed debug print\n        # print(f\"[DEBUG ENetV2 Epoch {epoch}] Base Dp: Cls={current_base_classifier_dropout:.3f}/Img={current_base_image_dropout:.3f} \"\n        #       f\"-> Scaled Dp: Cls={self.classifier_dropout.p:.3f}/Img={self.image_dropout.p:.3f} (Scale={dropout_scale:.3f})\")\n    # --- extract and forward methods remain the same ---\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x)\n        if x.dim() > 2:\n            x = x.view(x.size(0), -1)\n\n        x = self.image_dropout(x) # Use the dynamically adjusted dropout\n\n        if self.n_meta_features > 0:\n            if self.gradcam_mode and self.fixed_meta is not None:\n                x_meta = self.meta_attention(self.fixed_meta)\n            elif x_meta is not None:\n                x_meta = self.meta_attention(x_meta)\n            else:\n                raise ValueError(\"x_meta is required when n_meta_features > 0 and gradcam_mode is False\")\n\n            x_meta = self.meta_fc(x_meta)\n            x = torch.cat((x, x_meta), dim=1)\n\n        x = self.classifier_dropout(x) # Use the dynamically adjusted dropout\n        x = self.myfc(x)\n        x = torch.clamp(x, min=-20, max=20)\n        if torch.isnan(x).any() or torch.isinf(x).any():\n            # print(f\"Warning: NaN/Inf in logits at epoch {self.current_epoch}\") # Reduced verbosity\n            x = torch.nan_to_num(x, nan=0.0, posinf=20, neginf=-20)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model EfficientNet + ViT","metadata":{}},{"cell_type":"code","source":"# Updated HybridModel with Gradient Checkpointing\nfrom torch.utils.checkpoint import checkpoint\n# --- MODIFIED HybridModel ---\nclass HybridModel(nn.Module):\n    # Add dropout_scale_factors to __init__\n    def __init__(self, backbone, out_dim, n_meta_features=0, load_pretrained=True, image_size=448, dropout_scale_factors=None): # Added dropout_scale_factors\n        super(HybridModel, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.out_dim = out_dim\n        self.backbone = backbone\n        # Store the factors\n        self.dropout_scale_factors = dropout_scale_factors if dropout_scale_factors is not None else {v: 1.0 for v in range(3, 8)} # Default if None\n\n        # --- EfficientNet setup ---\n        import timm\n        self.enet = timm.create_model(backbone, pretrained=load_pretrained)\n        if load_pretrained:\n            print(f\"Hybrid: Loaded {backbone} ImageNet weights.\")\n        else:\n            print(f\"Hybrid: Initialized {backbone} random weights.\")\n        self.enet_features = self.enet.num_features\n        self.enet.reset_classifier(0, '')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        print(f\"ENet backbone: {backbone}, features: {self.enet_features}\")\n\n        # --- ViT setup (Keep original, small ViT config) ---\n        self.vit_config = ViTConfig(\n            image_size=image_size, patch_size=16, hidden_size=192, num_hidden_layers=4,\n            num_attention_heads=3, intermediate_size=768, hidden_dropout_prob=0.1, # Base ViT dropout\n            attention_probs_dropout_prob=0.1 # Base ViT dropout\n        )\n        self.vit = ViTModel(self.vit_config)\n        self.vit_features = self.vit_config.hidden_size\n        print(f\"ViT features dimension: {self.vit_features}\")\n\n        # --- Fusion Layer ---\n        fusion_dim = self.enet_features + self.vit_features\n        # Base dropout rate for fusion (will be scaled)\n        self.base_fusion_dropout_rate = 0.45\n        self.fusion = nn.Sequential(\n            nn.Linear(fusion_dim, 512), nn.BatchNorm1d(512), nn.SiLU(),\n            nn.Dropout(self.base_fusion_dropout_rate) # Placeholder, will be updated\n        )\n        print(f\"Fusion input dimension: {fusion_dim}\")\n\n        # --- Meta Pathway (if used) ---\n        combined_feature_dim = 512 # Output dim of fusion layer\n        if self.n_meta_features > 0:\n             # Increased complexity for meta pathway in Hybrid\n            meta_hidden_dim = 256\n            self.meta_attention = MetadataAttention(n_meta_features, hidden_dim=meta_hidden_dim // 2)\n            self.meta_fc = nn.Sequential(\n                nn.Linear(meta_hidden_dim // 2, meta_hidden_dim),\n                nn.BatchNorm1d(meta_hidden_dim),\n                nn.SiLU(),\n                nn.Dropout(p=0.4), # Keep reasonable\n                nn.Linear(meta_hidden_dim, 128),\n                nn.BatchNorm1d(128),\n                nn.SiLU(),\n                nn.Dropout(p=0.3) # Keep reasonable\n            )\n            combined_feature_dim += 128 # Add meta features dim\n            print(f\"  - Hybrid Meta Pathway: Attention({n_meta_features}->{meta_hidden_dim//2}), FC({meta_hidden_dim//2}->{meta_hidden_dim}->128)\")\n        else:\n             print(\"  - Hybrid Meta Pathway: Disabled\")\n\n        # --- Final Classifier ---\n        # Base dropout rate for classifier (will be scaled)\n        self.base_classifier_dropout_rate = 0.35\n        self.classifier = nn.Sequential(\n            nn.Dropout(self.base_classifier_dropout_rate), # Placeholder, will be updated\n            nn.Linear(combined_feature_dim, out_dim)\n        )\n\n        self.current_epoch = 0\n        self.gradcam_mode = False\n        self.fixed_meta = None\n        self.register_buffer('last_preds', None)\n        self.register_buffer('last_targets', None)\n\n    # MODIFIED set_epoch\n    def set_epoch(self, epoch):\n        self.current_epoch = epoch\n        enet_version = get_enet_version(self.backbone)\n        # Get the specific scaling factor for this model's config and ENet version\n        dropout_scale = self.dropout_scale_factors.get(enet_version, 1.0)\n        # print(f\"[DEBUG Hybrid Epoch {epoch}] ENet Version: {enet_version}, Dropout Scale: {dropout_scale:.4f}\") # Debug\n\n        # --- Dynamic Base Dropout Calculation (similar logic to enetv2) ---\n        max_epo_for_decay = 15\n        # Slightly different base rates potentially for hybrid\n        start_fusion_drop = 0.60\n        end_fusion_drop = 0.20\n        start_classifier_drop = 0.50\n        end_classifier_drop = 0.10\n\n        if epoch <= 5:\n            current_base_fusion_dropout = start_fusion_drop\n            current_base_classifier_dropout = start_classifier_drop\n        elif epoch <= max_epo_for_decay:\n            progress = (epoch - 5) / (max_epo_for_decay - 5)\n            current_base_fusion_dropout = start_fusion_drop - progress * (start_fusion_drop - end_fusion_drop)\n            current_base_classifier_dropout = start_classifier_drop - progress * (start_classifier_drop - end_classifier_drop)\n        else:\n            current_base_fusion_dropout = end_fusion_drop\n            current_base_classifier_dropout = end_classifier_drop\n\n        # Apply scaling and cap\n        adjusted_fusion_dropout = min(max(current_base_fusion_dropout * dropout_scale, 0.01), 0.95)\n        adjusted_classifier_dropout = min(max(current_base_classifier_dropout * dropout_scale, 0.01), 0.90)\n\n        # Apply to layers (access dropout layers by index)\n        self.fusion[3].p = adjusted_fusion_dropout          # Dropout is the 4th element (index 3)\n        self.classifier[0].p = adjusted_classifier_dropout  # Dropout is the 1st element (index 0)\n\n        # Optional: More detailed debug print\n        # print(f\"[DEBUG Hybrid Epoch {epoch}] Base Dp: Fus={current_base_fusion_dropout:.3f}/Cls={current_base_classifier_dropout:.3f} \"\n        #       f\"-> Scaled Dp: Fus={self.fusion[3].p:.3f}/Cls={self.classifier[0].p:.3f} (Scale={dropout_scale:.3f})\")\n\n    # --- extract and forward methods remain the same (using checkpointing) ---\n    def extract(self, x):\n        def enet_forward(x_enet):\n            features = self.enet.forward_features(x_enet)\n            pooled = self.pool(features)\n            return pooled.view(pooled.size(0), -1)\n\n        def vit_forward(x_vit):\n            # IMPORTANT: Ensure ViT receives input compatible with its patch embedding\n            # If input `x` is already correct size for ViT (e.g., 224x224 or image_size), use it directly.\n            # If ENet modifies spatial dims, you might need separate transforms or resizing for ViT.\n            # Assuming `x` is suitable for ViT here.\n            return self.vit(pixel_values=x_vit).last_hidden_state[:, 0] # CLS token\n\n        # Use reentrant=False if compatible with your PyTorch version (>1.11 recommended)\n        # It can be slightly faster and use less memory than the default reentrant=True\n        cnn_features = enet_forward(x)\n        vit_features = vit_forward(x)\n\n        combined = torch.cat((cnn_features, vit_features), dim=1)\n        fused = self.fusion(combined) # Apply fusion (including its dynamic dropout)\n        return fused\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x) # Gets fused features (CNN+ViT) after fusion dropout\n\n        if self.n_meta_features > 0:\n            if self.gradcam_mode and self.fixed_meta is not None:\n                 meta_attended = self.meta_attention(self.fixed_meta)\n            elif x_meta is not None:\n                 meta_attended = self.meta_attention(x_meta)\n            else:\n                raise ValueError(\"x_meta required for Hybrid model when n_meta_features > 0\")\n\n            meta_processed = self.meta_fc(meta_attended)\n            x = torch.cat((x, meta_processed), dim=1)\n\n        # Classifier dropout is applied within the self.classifier sequential block\n        output = self.classifier(x)\n        output = torch.clamp(output, min=-20, max=20) # Clamp final output\n        if torch.isnan(output).any() or torch.isinf(output).any():\n             output = torch.nan_to_num(output, nan=0.0, posinf=20, neginf=-20)\n        return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Freeze Function","metadata":{}},{"cell_type":"code","source":"def progressive_unfreeze_v3(\n    model,\n    optimizer, # Pass the current optimizer\n    epoch,\n    freeze_initially_until_block, # Block index used in partial_freeze_enet (e.g., 4)\n    start_unfreeze_epoch,         # When to start unfreezing (e.g., 7) - NOW CONDITIONAL\n    full_unfreeze_epoch,          # When to unfreeze everything & reset optimizer (e.g., 15) - NOW CONDITIONAL\n    final_enet_lr_mult=0.3,       # Base Multiplier for backbone LR vs base LR\n    final_vit_lr_mult=0.8,        # Base Multiplier for ViT LR (if hybrid)\n    final_head_lr_mult=1.0,       # Base Multiplier for head/meta LR\n    base_lr=1e-3,                 # Global Base LR (e.g., init_lr)\n    enet_type=None,               # Needed for scaling factors\n    lr_scale_factors=None         # The dictionary of BIASED scaling factors\n):\n    \"\"\"\n    Unfreezes EfficientNet blocks sequentially from deep to shallow.\n    Resets optimizer only once at full_unfreeze_epoch.\n    MODIFIED to use biased lr_scale_factors when resetting optimizer.\n    \"\"\"\n    # Ensure we are using the base model\n    model_base = model.module if isinstance(model, nn.DataParallel) else model\n\n    # --- Phase 1: Before unfreezing starts ---\n    if epoch < start_unfreeze_epoch:\n        # print(f\"Epoch {epoch}: Keeping layers frozen (Before Start Epoch {start_unfreeze_epoch}).\") # Optional debug\n        return optimizer, False # Return original optimizer, indicate no change\n\n    # --- Get Max Block Index (as before) ---\n    max_block_idx = get_max_enet_block_index(model_base)\n    if max_block_idx == -1:\n         print(\"Warning: Could not determine max block index. Cannot perform sequential unfreeze.\")\n         return optimizer, False\n\n\n    # --- Phase 3: Full unfreeze and optimizer reset ---\n    if epoch == full_unfreeze_epoch:\n        print(f\"Epoch {epoch}: Fully unfreezing ALL backbone layers and resetting optimizer.\")\n        # ... (unfreezing parameters logic remains the same) ...\n        unfrozen_count = 0\n        for name, param in model_base.named_parameters(): # Unfreeze everything\n            if not param.requires_grad:\n                 param.requires_grad = True\n                 unfrozen_count += 1\n        if unfrozen_count > 0:\n             print(f\"  - Unfroze {unfrozen_count} previously frozen parameters.\")\n\n\n        # --- *** MODIFIED: Create NEW optimizer with differential & SCALED LRs *** ---\n        enet_version = get_enet_version(enet_type)\n        # Get the BIASED lr scale factor for this specific ENet version\n        lr_scale = lr_scale_factors.get(enet_version, 1.0) if lr_scale_factors else 1.0\n        print(f\"  - Applying LR Scale Factor {lr_scale:.4f} (from biased factors) for ENet v{enet_version}\")\n\n        # Define final learning rates using base_lr, multipliers, AND the biased scale factor\n        # Apply the scale factor primarily to the parts we want to bias most (ENet, maybe ViT?)\n        # Head/Meta LR often benefits from being higher relative to backbone, maybe scale less?\n        final_enet_lr = base_lr * final_enet_lr_mult * lr_scale\n        final_vit_lr = base_lr * final_vit_lr_mult * lr_scale # Scale ViT similarly to ENet for hybrid consistency? Or use a different scale? Let's scale it too.\n        final_head_lr = base_lr * final_head_lr_mult * (lr_scale * 0.5 + 0.5) # Dampen the scaling effect on head LR? Or apply fully? Let's apply fully for simplicity.\n        final_head_lr = base_lr * final_head_lr_mult * lr_scale\n        final_meta_lr = base_lr * final_head_lr_mult * lr_scale # Meta layers usually use head LR, scale similarly\n\n        print(f\"  - Final LR settings (BaseLR={base_lr:.1e}, Scale={lr_scale:.3f}):\")\n        print(f\"    ENet={final_enet_lr:.2e} (Mult={final_enet_lr_mult:.2f})\")\n        if hasattr(model_base, 'vit'): print(f\"    ViT ={final_vit_lr:.2e} (Mult={final_vit_lr_mult:.2f})\")\n        if hasattr(model_base, 'fusion') or hasattr(model_base,'myfc') or hasattr(model_base,'classifier'): print(f\"    Head={final_head_lr:.2e} (Mult={final_head_lr_mult:.2f})\")\n        if hasattr(model_base, 'meta_attention'): print(f\"    Meta={final_meta_lr:.2e} (Mult={final_head_lr_mult:.2f})\")\n\n\n        # --- Define Parameter Groups Robustly (as before) ---\n        param_groups = []\n        all_param_ids = set() # Keep track of params assigned to groups\n\n        # Group 1: ENet parameters\n        if hasattr(model_base, 'enet'):\n            enet_params = [p for n, p in model_base.enet.named_parameters() if p.requires_grad]\n            if enet_params:\n                param_groups.append({'params': enet_params, 'lr': final_enet_lr, 'weight_decay': 0.01}) # Lower WD for backbone\n                all_param_ids.update(id(p) for p in enet_params)\n\n        # Group 2: ViT parameters (if hybrid)\n        if hasattr(model_base, 'vit'):\n            vit_params = [p for n, p in model_base.vit.named_parameters() if p.requires_grad and id(p) not in all_param_ids]\n            if vit_params:\n                param_groups.append({'params': vit_params, 'lr': final_vit_lr, 'weight_decay': 0.02}) # Slightly higher WD?\n                all_param_ids.update(id(p) for p in vit_params)\n\n        # Group 3: Fusion parameters (if hybrid)\n        if hasattr(model_base, 'fusion'):\n            fusion_params = [p for n, p in model_base.fusion.named_parameters() if p.requires_grad and id(p) not in all_param_ids]\n            if fusion_params:\n                param_groups.append({'params': fusion_params, 'lr': final_head_lr, 'weight_decay': 0.05}) # Higher WD for head\n                all_param_ids.update(id(p) for p in fusion_params)\n\n        # Group 4: Meta layers\n        meta_params_list = []\n        if hasattr(model_base, 'meta_attention'): meta_params_list.extend(list(model_base.meta_attention.parameters()))\n        if hasattr(model_base, 'meta_fc'): meta_params_list.extend(list(model_base.meta_fc.parameters()))\n        unique_meta_params = [p for p in meta_params_list if p.requires_grad and id(p) not in all_param_ids]\n        if unique_meta_params:\n             param_groups.append({'params': unique_meta_params, 'lr': final_meta_lr, 'weight_decay': 0.05})\n             all_param_ids.update(id(p) for p in unique_meta_params)\n\n        # Group 5: Final Classifier (myfc or classifier layer)\n        classifier_params_list = []\n        if hasattr(model_base, 'myfc'): classifier_params_list.extend(list(model_base.myfc.parameters()))\n        if hasattr(model_base, 'classifier'): classifier_params_list.extend(list(model_base.classifier.parameters()))\n        unique_classifier_params = [p for p in classifier_params_list if p.requires_grad and id(p) not in all_param_ids]\n        if unique_classifier_params:\n            param_groups.append({'params': unique_classifier_params, 'lr': final_head_lr, 'weight_decay': 0.05})\n            all_param_ids.update(id(p) for p in unique_classifier_params)\n\n        # Catch any remaining trainable parameters\n        remaining_params = [p for n,p in model_base.named_parameters() if p.requires_grad and id(p) not in all_param_ids]\n        if remaining_params:\n             print(f\"  - WARNING: {len(remaining_params)} trainable parameters were not assigned to an optimizer group. Adding with head LR.\")\n             param_groups.append({'params': remaining_params, 'lr': final_head_lr, 'weight_decay': 0.05})\n\n        # Create the new optimizer\n        if not param_groups:\n            raise RuntimeError(\"Cannot create new optimizer: No parameter groups formed.\")\n        new_optimizer = optim.AdamW(param_groups, eps=1e-7) # WD applied per group\n        print(f\"Optimizer recreated with {len(param_groups)} parameter groups using BIASED scaled LRs.\")\n        return new_optimizer, True # Return NEW optimizer, indicate change happened\n\n    # --- Phase 2: Intermediate unfreezing steps ---\n    elif epoch >= start_unfreeze_epoch and epoch < full_unfreeze_epoch:\n        # Logic for unfreezing blocks sequentially remains the same\n        # ... (your existing sequential unfreezing logic) ...\n        # Correct calculation for blocks to unfreeze sequentially\n        blocks_to_unfreeze_sequentially = list(range(max_block_idx, freeze_initially_until_block, -1))\n        num_unfreeze_stages = len(blocks_to_unfreeze_sequentially)\n\n        if num_unfreeze_stages > 0:\n             total_unfreeze_epochs_span = full_unfreeze_epoch - start_unfreeze_epoch\n             epochs_per_stage = max(1, math.ceil(total_unfreeze_epochs_span / num_unfreeze_stages))\n             current_stage_idx = (epoch - start_unfreeze_epoch) // epochs_per_stage\n\n             if current_stage_idx < num_unfreeze_stages:\n                 block_idx_to_unfreeze = blocks_to_unfreeze_sequentially[current_stage_idx]\n                 unfrozen_something_in_stage = False\n                 # ... (rest of logic to find and unfreeze params in block_idx_to_unfreeze) ...\n                 for name, param in model_base.enet.named_parameters():\n                      layer_name_parts = name.split('.')\n                      is_target_block = False\n                      if 'blocks' in layer_name_parts:\n                           try:\n                               block_idx_in_name = int(layer_name_parts[layer_name_parts.index('blocks') + 1])\n                               if block_idx_in_name == block_idx_to_unfreeze:\n                                   is_target_block = True\n                           except (IndexError, ValueError, TypeError): pass\n\n                      if is_target_block and not param.requires_grad:\n                          param.requires_grad = True\n                          unfrozen_something_in_stage = True\n\n\n                 if unfrozen_something_in_stage:\n                     print(f\"Epoch {epoch}: Unfroze enet.blocks.{block_idx_to_unfreeze}\")\n                     # Do NOT reset optimizer here. Return the original one.\n                     return optimizer, False # No optimizer change, but layers unfroze\n\n    # If it's not start_unfreeze_epoch or full_unfreeze_epoch, and no intermediate unfreeze happened\n    return optimizer, False # Return original optimizer, indicate no change","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Component","metadata":{}},{"cell_type":"code","source":"# Fix Warmup Bug\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and Valid","metadata":{}},{"cell_type":"code","source":"# Utility function to get resource usage\ndef get_resource_usage():\n    if torch.cuda.is_available():\n        mem_alloc = torch.cuda.memory_allocated() / 1024**2  # MB\n        mem_max = torch.cuda.max_memory_allocated() / 1024**2  # MB\n        return {\"gpu_memory_allocated\": mem_alloc, \"gpu_max_memory\": mem_max}\n    else:\n        import psutil\n        cpu_usage = psutil.cpu_percent(interval=1)\n        ram_usage = psutil.virtual_memory().percent\n        return {\"cpu_usage\": cpu_usage, \"ram_usage\": ram_usage}\n        \nclass TemperatureScaling:\n    def __init__(self, model, device):\n        self.model = model\n        self.device = device\n        # Initialize log_temperature as a learnable parameter starting at 0 (exp(0) = 1)\n        self.log_temperature = nn.Parameter(torch.zeros(1).to(device))\n\n    def calibrate(self, loader, max_iter=50):\n        \"\"\"\n        Optimizes the temperature using validation data with NLL as the loss.\n        Ensures temperature remains positive via exponential parameterization.\n        \"\"\"\n        self.model.eval()\n        nll_criterion = nn.CrossEntropyLoss()\n        optimizer = optim.LBFGS([self.log_temperature], lr=0.01, max_iter=max_iter)\n\n        # Collect logits and targets from validation data\n        all_logits = []\n        all_targets = []\n        with torch.no_grad():\n            for batch in loader:\n                if hasattr(self.model, 'module') and self.model.module.n_meta_features > 0:\n                    (images, meta), target = batch\n                    images, meta, target = images.to(self.device), meta.to(self.device), target.to(self.device)\n                    logits = self.model(images, meta)\n                else:\n                    images, target = batch\n                    images, target = images.to(self.device), target.to(self.device)\n                    logits = self.model(images)\n                all_logits.append(logits)\n                all_targets.append(target)\n        \n        logits = torch.cat(all_logits)\n        targets = torch.cat(all_targets)\n\n        # Closure for LBFGS optimization\n        def nll_closure():\n            optimizer.zero_grad()\n            temperature = torch.exp(self.log_temperature)  # Ensures temperature > 0\n            scaled_logits = logits / temperature\n            loss = nll_criterion(scaled_logits, targets)\n            loss.backward()\n            return loss\n\n        # Optimize log_temperature\n        optimizer.step(nll_closure)\n        optimal_temperature = torch.exp(self.log_temperature).item()\n        print(f\"Optimal temperature: {optimal_temperature:.4f}\")\n        return optimal_temperature\n\n    def forward(self, logits):\n        \"\"\"\n        Applies the learned temperature to logits to obtain calibrated probabilities.\n        \"\"\"\n        temperature = torch.exp(self.log_temperature)\n        return torch.softmax(logits / temperature, dim=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Early Stopping Mechanism","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(\n        self,\n        patience: int = 10,  # Increased from 3 to 10\n        mode: str = 'max',\n        delta: float = 0.005,  # Small relative improvement\n        relative_delta: bool = True,  # Use relative delta\n        warm_up: int = 9,  # Extended to cover frozen phase (epochs 1-9)\n        verbose: bool = True,\n        checkpoint_path: str = 'best_model.pth',\n        score_weights: Optional[Dict[str, float]] = None\n    ):\n        if mode not in ['min', 'max']:\n            raise ValueError(\"mode must be 'min' or 'max'\")\n        self.patience = patience\n        self.mode = mode\n        self.delta = delta\n        self.relative_delta = relative_delta\n        self.warm_up = warm_up\n        self.verbose = verbose\n        self.checkpoint_path = checkpoint_path\n        self.counters: Dict[str, int] = {}\n        self.best_scores: Dict[str, float] = {}\n        self.best_epoch: Dict[str, int] = {}\n        self.early_stop = False\n        self._is_first = True\n        self.score_weights = score_weights or {\n            'binary_auc': 0.4,      # Increased to prioritize AUC target\n            'binary_recall': 0.2,   # Reduced slightly to balance\n            'multiclass_auc': 0.3,  # Kept to ensure multiclass consideration\n            'binary_specificity': 0.05,\n            'val_loss': 0.05        # Minimize, low weight\n        }\n        # Validate score_weights\n        if self.score_weights:\n            total_weight = sum(self.score_weights.values())\n            if total_weight <= 0:\n                raise ValueError(\"Total weight in score_weights must be positive.\")\n            # Normalize weights to sum to 1.0 (optional)\n            self.score_weights = {k: v / total_weight for k, v in self.score_weights.items()}\n\n    def reset(self):\n        \"\"\"Reset the early stopping object to its initial state.\"\"\"\n        self.counters = {}\n        self.best_scores = {}\n        self.best_epoch = {}\n        self.early_stop = False\n        self._is_first = True\n\n    def __call__(\n        self,\n        metrics: Union[Dict[str, float], float],\n        model: Optional[torch.nn.Module] = None,\n        epoch: Optional[int] = None\n    ):\n        if epoch is None:\n            raise ValueError(\"epoch must be provided.\")\n        if epoch <= self.warm_up:\n            if self.verbose:\n                print(f\"Epoch {epoch} in warm-up period, skipping early stopping.\")\n            return\n\n        if isinstance(metrics, (int, float)):\n            metrics = {'val_metric': metrics}\n\n        # Compute composite score\n        score = 0.0\n        for metric_name, val_metric in metrics.items():\n            if not isinstance(val_metric, (int, float)):\n                raise ValueError(f\"Metric {metric_name} must be a number, got {type(val_metric)}\")\n            if metric_name not in metrics:\n                continue  # Skip missing metrics\n            weight = self.score_weights.get(metric_name, 0)\n            if weight > 0:\n                # Transform val_loss (minimize) to fit max mode\n                adjusted_score = -val_metric if metric_name == 'val_loss' else val_metric\n                score += adjusted_score * weight\n\n        current_delta = self.delta if not self.relative_delta else self.delta * abs(self.best_scores.get('composite', 0))\n\n        if self._is_first or self.best_scores.get('composite') is None:\n            self.best_scores['composite'] = score\n            self.best_epoch['composite'] = epoch\n            self.counters['composite'] = 0\n            self._is_first = False\n            if model and self.checkpoint_path:\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'best_scores': self.best_scores,\n                    'best_epoch': self.best_epoch\n                }, self.checkpoint_path)\n                if self.verbose:\n                    print(f\"Initial best composite score: {score:.6f} at epoch {epoch}, model saved to {self.checkpoint_path}\")\n        elif score > self.best_scores['composite'] + current_delta:\n            self.best_scores['composite'] = score\n            self.best_epoch['composite'] = epoch\n            self.counters['composite'] = 0\n            if model and self.checkpoint_path:\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'best_scores': self.best_scores,\n                    'best_epoch': self.best_epoch\n                }, self.checkpoint_path)\n                if self.verbose:\n                    print(f\"New best composite score: {score:.6f} at epoch {epoch}, model saved to {self.checkpoint_path}\")\n        else:\n            self.counters['composite'] = self.counters.get('composite', 0) + 1\n            if self.verbose:\n                print(f\"No improvement in composite score. Counter: {self.counters['composite']}/{self.patience}\")\n                for metric_name, val_metric in metrics.items():\n                    print(f\"  {metric_name}: {val_metric:.6f}\")\n            if self.counters['composite'] >= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print(f\"Early stopping triggered after {epoch} epochs due to composite score.\")\n\ndef get_best_scores(self) -> Dict[str, float]:\n        \"\"\"Return the best scores for all monitored metrics.\"\"\"\n        return {'composite': self.best_scores.get('composite', float('-inf') if self.mode == 'max' else float('inf'))}\n\ndef get_best_epoch(self) -> Dict[str, int]:\n        \"\"\"Return the epoch of the best score for all monitored metrics.\"\"\"\n        return {'composite': self.best_epoch.get('composite', 0)}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Epoch","metadata":{}},{"cell_type":"code","source":"import time\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\n# Make sure get_resource_usage is defined elsewhere or remove the call\n\ndef train_epoch(model, loader, optimizer, experiment, epoch, scaler=None, accum_steps=1, criterion_multi=None, mel_idx=None, lambda_binary=0.75, device=None):\n    \"\"\"\n    Training epoch function.\n    REMOVED: AdaBoost-style weight updates.\n    \"\"\"\n    if criterion_multi is None or mel_idx is None:\n        raise ValueError(\"criterion_multi and mel_idx must be provided to train_epoch\")\n\n    use_device = device is not None\n    if not use_device:\n        print(\"Warning: No device provided; defaulting to 'cuda' if available\")\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.train() # Ensure model is in training mode\n    train_loss_list = [] # Store loss of each batch (before accumulation division)\n    train_correct = 0\n    train_total = 0\n    start_time = time.time()\n    optimizer.zero_grad() # Zero gradients at the start of the epoch\n\n    # Initialize tqdm progress bar\n    pbar = tqdm(loader, desc=f\"Epoch {epoch} - Loss: N/A, Acc: N/A\", total=len(loader))\n\n    for batch_idx, batch in enumerate(pbar):\n        # --- Data Handling ---\n        if hasattr(model.module, 'n_meta_features') and model.module.n_meta_features > 0: # Check n_meta_features on the base model\n            (images, meta), target = batch\n            images, meta, target = images.to(device), meta.to(device), target.to(device)\n        else:\n            images, target = batch\n            images, target = images.to(device), target.to(device)\n\n        # --- Forward Pass ---\n        if scaler: # Using AMP\n            with torch.cuda.amp.autocast():\n                logits = model(images, meta) if (hasattr(model.module, 'n_meta_features') and model.module.n_meta_features > 0) else model(images)\n                # --- Loss Calculation ---\n                multiclass_loss = criterion_multi(logits, target)\n                binary_target = (target == mel_idx).float()\n                binary_logits = logits[:, mel_idx]\n                binary_loss = F.binary_cross_entropy_with_logits(binary_logits, binary_target) # Use BCEWithLogits\n                total_loss_unscaled = multiclass_loss + lambda_binary * binary_loss\n                total_loss = total_loss_unscaled / accum_steps # Scale loss for accumulation\n            # --- Backward Pass (AMP) ---\n            scaler.scale(total_loss).backward()\n        else: # Not using AMP\n            logits = model(images, meta) if (hasattr(model.module, 'n_meta_features') and model.module.n_meta_features > 0) else model(images)\n            # --- Loss Calculation ---\n            multiclass_loss = criterion_multi(logits, target)\n            binary_target = (target == mel_idx).float()\n            binary_logits = logits[:, mel_idx]\n            binary_loss = F.binary_cross_entropy_with_logits(binary_logits, binary_target) # Use BCEWithLogits\n            total_loss_unscaled = multiclass_loss + lambda_binary * binary_loss\n            total_loss = total_loss_unscaled / accum_steps # Scale loss for accumulation\n            # --- Backward Pass ---\n            total_loss.backward()\n\n        # Store unscaled loss for epoch average reporting\n        train_loss_list.append(total_loss_unscaled.item())\n\n        # --- Accuracy Tracking (using the same logits) ---\n        with torch.no_grad(): # No need gradients for accuracy calculation\n             preds = logits.argmax(dim=1)\n             batch_correct = (preds == target).sum().item()\n             batch_total = target.size(0)\n             train_correct += batch_correct\n             train_total += batch_total\n\n        # --- Optimization Step ---\n        if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(loader):\n            if scaler:\n                scaler.step(optimizer) # Unscales gradients and steps optimizer\n                scaler.update()        # Updates scaler for next iteration\n            else:\n                optimizer.step()       # Standard optimizer step\n            optimizer.zero_grad()      # Zero gradients *after* stepping\n\n        # --- Update Progress Bar ---\n        # Calculate metrics based on accumulated values so far\n        avg_loss_so_far = np.mean(train_loss_list) if train_loss_list else 0.0\n        acc_so_far = (train_correct / train_total) * 100.0 if train_total > 0 else 0.0\n        pbar.set_description(f\"Epoch {epoch} - Loss: {avg_loss_so_far:.4f}, Acc: {acc_so_far:.2f}%\")\n        # pbar.set_postfix(batch=batch_idx + 1) # Optional: show batch number\n\n    # --- End of Epoch ---\n    pbar.close()\n    avg_train_loss = np.mean(train_loss_list) if train_loss_list else 0.0 # Final average loss for the epoch\n    train_acc = (train_correct / train_total) * 100.0 if train_total > 0 else 0.0\n    epoch_time = time.time() - start_time\n\n    # --- Resource Usage ---\n    try:\n        resources = get_resource_usage()\n    except NameError:\n        resources = {} # Handle if function not defined\n        print(\"Warning: get_resource_usage() not defined.\")\n\n    # --- Print Epoch Summary ---\n    print(\n        f\"Epoch {epoch} - Training Time: {epoch_time:.2f}s, Avg Loss: {avg_train_loss:.5f}, \"\n        f\"Acc: {train_acc:.2f}%, Resources: {resources}\"\n    )\n\n    # --- Logging to W&B ---\n    if experiment:\n        log_data = {\n            \"train_loss\": avg_train_loss,\n            \"train_acc\": train_acc,\n            \"train_epoch_time_seconds\": epoch_time,\n        }\n        # Add resource usage if available and it's a dictionary\n        if isinstance(resources, dict):\n             log_data.update({f\"train_{k}\": v for k, v in resources.items()})\n        experiment.log(log_data, step=epoch)\n\n    # --- Return average loss for the epoch ---\n    return avg_train_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validation Epoch","metadata":{}},{"cell_type":"code","source":"def val_epoch(model, loader, experiment, epoch, n_test=1, recalib_interval=5, # REMOVED mc_samples\n              criterion_multi=None, mel_idx=None, lambda_binary=0.5, device=None, use_amp=True):\n    \"\"\"\n    Validation epoch function.\n    REMOVED: MC Dropout logic and uncertainty calculations.\n    KEPT: Temperature Scaling.\n    \"\"\"\n    if criterion_multi is None or mel_idx is None:\n        raise ValueError(\"criterion_multi and mel_idx must be provided to val_epoch\")\n    if device is None:\n        print(\"Warning: No device provided; defaulting to 'cuda' if available\")\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.eval()  # Set model STRICTLY to eval mode for validation\n    out_dim = model.module.out_dim\n\n    val_loss_batch_list = [] # Store average loss per batch\n    PROBS_ALL = []          # Store predicted probabilities for the epoch\n    TARGETS = []            # Store true targets for the epoch\n    start_time = time.time()\n\n    # --- Temperature Scaling Setup ---\n    temp_scaler = TemperatureScaling(model, device)\n    optimal_temp = None\n    if epoch > 1 and epoch % recalib_interval == 1:\n        print(f\"Calibrating model with Temperature Scaling at epoch {epoch}...\")\n        optimal_temp = temp_scaler.calibrate(loader)\n        if experiment and optimal_temp is not None:\n            experiment.log({\"optimal_temperature\": optimal_temp}, step=epoch)\n\n    current_temp = optimal_temp if optimal_temp is not None else (torch.exp(temp_scaler.log_temperature).item() if hasattr(temp_scaler, 'log_temperature') else 1.0)\n    print(f\"Using temperature: {current_temp:.4f} for validation epoch {epoch}\")\n    # --- End Temperature Scaling Setup ---\n\n    # --- Initialize Metrics ---\n    multiclass_acc = MulticlassAccuracy(num_classes=out_dim, average='macro').to(device)\n    multiclass_f1 = MulticlassF1Score(num_classes=out_dim, average='macro').to(device)\n    multiclass_auc = MulticlassAUROC(num_classes=out_dim, average='macro', thresholds=None).to(device)\n    multiclass_confmat = MulticlassConfusionMatrix(num_classes=out_dim).to(device)\n    binary_auc = BinaryAUROC(thresholds=None).to(device)\n\n    with torch.no_grad():\n        pbar = tqdm(loader, desc=f\"Validating Epoch {epoch}\", total=len(loader))\n        for batch_idx, batch in enumerate(pbar):\n            # --- Unpack Batch ---\n            if hasattr(model.module, 'n_meta_features') and model.module.n_meta_features > 0:\n                (images, meta), target = batch\n                images, meta, target = images.to(device), meta.to(device), target.to(device)\n            else:\n                images, target = batch\n                images, target = images.to(device), target.to(device)\n            batch_size = images.shape[0]\n\n            # --- Single Inference Pass ---\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                if hasattr(model.module, 'n_meta_features') and model.module.n_meta_features > 0:\n                    logits = model(images, meta)\n                else:\n                    logits = model(images)\n\n                # Clamp logits and handle potential NaN/Inf\n                logits = torch.clamp(logits, min=-20, max=20)\n                if torch.isnan(logits).any() or torch.isinf(logits).any():\n                    print(f\"Warning: NaN/Inf in raw logits at batch {batch_idx}\")\n                    logits = torch.nan_to_num(logits, nan=0.0, posinf=20, neginf=-20)\n\n                # --- Calculate Loss (using raw logits) ---\n                multiclass_loss = criterion_multi(logits, target)\n                binary_target = (target == mel_idx).float()\n                binary_logits = logits[:, mel_idx]\n                binary_loss = nn.functional.binary_cross_entropy_with_logits(\n                    torch.clamp(binary_logits, -10, 10), binary_target, reduction='mean'\n                )\n                total_loss = multiclass_loss + lambda_binary * binary_loss\n\n                # --- Calculate probabilities using the defined current_temp ---\n                current_probs = torch.softmax(logits / current_temp, dim=1)\n\n                # Handle potential NaN/Inf in probabilities and clamp\n                if torch.isnan(current_probs).any() or torch.isinf(current_probs).any():\n                     print(f\"Warning: NaN/Inf in softmax probs at batch {batch_idx}\")\n                     current_probs = torch.nan_to_num(current_probs, nan=0.5, posinf=1.0, neginf=0.0)\n                current_probs = torch.clamp(current_probs, 1e-6, 1.0 - 1e-6)\n\n            # --- Store Batch Results ---\n            if torch.isnan(total_loss) or torch.isinf(total_loss):\n                print(f\"Warning: NaN or Inf in batch total_loss at batch {batch_idx}\")\n                total_loss = torch.tensor(0.0, device=device) # Assign zero loss if issue\n            val_loss_batch_list.append(total_loss.item())\n\n            PROBS_ALL.append(current_probs) # Append probs from single pass\n            TARGETS.append(target)\n\n            # --- Update Metrics using current_probs ---\n            multiclass_acc.update(current_probs, target)\n            multiclass_f1.update(current_probs, target)\n            multiclass_auc.update(current_probs, target)\n            multiclass_confmat.update(current_probs.argmax(dim=1), target)\n            binary_targets_batch = (target == mel_idx).float()\n            binary_probs_batch = current_probs[:, mel_idx]\n            binary_auc.update(binary_probs_batch, binary_targets_batch)\n\n            pbar.set_postfix(loss=total_loss.item())\n        pbar.close()\n\n    # --- Aggregate Epoch Results ---\n    if not val_loss_batch_list:\n        print(f\"Epoch {epoch} - No batches processed during validation.\")\n        # Return default/dummy values safely matching the *new* reduced structure\n        return (\n            0.0, 0.5, 0.5, # val_loss, binary_auc, multiclass_auc\n            np.array([]), np.array([]), # PROBS, TARGETS\n            0.0, 0.0, 0.0, 0.0, 0.0, # binary_acc, prec, recall, f1, spec\n            0.0, 0.0, [], [], # multiclass_acc, f1, multi_cm, binary_cm\n            1.0, # current_temp\n            None # roc_data\n        )\n\n    val_loss_avg = np.mean(val_loss_batch_list)\n    epoch_time = time.time() - start_time\n    try:\n        resources = get_resource_usage()\n    except NameError:\n        resources = {}\n        print(\"Warning: get_resource_usage() not defined.\")\n\n    PROBS_ALL = torch.cat(PROBS_ALL, dim=0)\n    TARGETS = torch.cat(TARGETS, dim=0)\n\n    PROBS = PROBS_ALL.cpu().numpy()\n    TARGETS = TARGETS.cpu().numpy()\n\n    # --- Compute Final Metrics ---\n    print(f\"Epoch {epoch} - Aggregated PROBS shape: {PROBS.shape}, TARGETS shape: {TARGETS.shape}\")\n    if PROBS.shape[0] == 0 or TARGETS.shape[0] == 0:\n         print(f\"Epoch {epoch} - Empty aggregated results, cannot compute metrics.\")\n         # Return dummy values matching the new structure\n         return (\n            val_loss_avg, 0.5, 0.5,\n            PROBS, TARGETS,\n            0.0, 0.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, [], [],\n            current_temp, None\n         )\n\n    multiclass_acc_val = multiclass_acc.compute().item() * 100.0\n    multiclass_f1_val = multiclass_f1.compute().item()\n    multiclass_auc_val = multiclass_auc.compute().item()\n    multiclass_conf_matrix = multiclass_confmat.compute().cpu().numpy().tolist()\n    binary_auc_val = binary_auc.compute().item()\n\n    # --- Rest of the metric calculations (thresholding, binary metrics) ---\n    binary_targets_np = (TARGETS == mel_idx).astype(np.float32)\n    binary_probs_np = PROBS[:, mel_idx]\n    # Slightly adjust probs for threshold finding robustness\n    binary_probs_np_adjusted = np.minimum(binary_probs_np * 1.1, 1.0)\n\n    # Find optimal threshold based on F1 from PR curve (fine-grained search)\n    best_threshold = 0.5 # Default\n    best_f1 = 0.0\n    f1_history = []\n    try: # Added try-except block for robustness\n        precision, recall, pr_thresholds = precision_recall_curve(binary_targets_np, binary_probs_np_adjusted)\n        optimal_threshold_pr = 0.5 # Default\n        best_f1_from_pr = 0.0\n        if len(precision) > 1 and len(recall) > 1:\n            f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-6)\n            if len(f1_scores) > 0:\n                optimal_idx_pr = np.argmax(f1_scores)\n                best_f1_from_pr = f1_scores[optimal_idx_pr]\n                optimal_threshold_pr = pr_thresholds[optimal_idx_pr]\n                print(f\"Epoch {epoch} - PR-based optimal threshold: {optimal_threshold_pr:.4f}, F1: {best_f1_from_pr:.4f}\")\n            else: print(f\"Epoch {epoch} - PR-based optimal threshold: {optimal_threshold_pr:.4f} (fallback - no valid F1 scores)\")\n        else: print(f\"Epoch {epoch} - PR-based optimal threshold: {optimal_threshold_pr:.4f} (fallback - insufficient P/R points)\")\n\n        thresholds_to_test = np.linspace(max(0, optimal_threshold_pr - 0.05), min(1, optimal_threshold_pr + 0.05), 50)\n        best_f1 = 0; best_threshold = optimal_threshold_pr;\n        for thresh in thresholds_to_test:\n            preds = (binary_probs_np_adjusted > thresh).astype(np.float32)\n            f1 = f1_score(binary_targets_np, preds, zero_division=0)\n            f1_history.append((thresh, f1))\n            if f1 > best_f1: best_f1 = f1; best_threshold = thresh\n        print(f\"Epoch {epoch} - Best F1 threshold (fine-grained): {best_threshold:.4f}, Best F1: {best_f1:.4f}\")\n    except ValueError as ve:\n        print(f\"Warning: Error during threshold optimization (likely due to single class in batch/epoch): {ve}\")\n        # Keep default best_threshold = 0.5\n\n    # Calculate metrics using best_threshold\n    binary_preds_best = (binary_probs_np_adjusted > best_threshold).astype(np.float32)\n    binary_conf_matrix_best = [[0,0],[0,0]] # Default\n    binary_specificity_best, binary_precision_best, binary_recall_best, binary_f1_best, binary_acc_best = 0,0,0,0,0\n    if len(binary_targets_np) > 0:\n        try:\n            binary_conf_matrix_best = confusion_matrix(binary_targets_np, binary_preds_best).tolist()\n            if len(np.array(binary_conf_matrix_best).ravel()) == 4:\n                 tn_best, fp_best, fn_best, tp_best = np.array(binary_conf_matrix_best).ravel()\n                 binary_specificity_best = tn_best / (tn_best + fp_best) if (tn_best + fp_best) > 0 else 0.0\n            else: tn_best, fp_best, fn_best, tp_best = 0,0,0,0 # Handle case where CM is not 2x2\n\n            binary_precision_best = precision_score(binary_targets_np, binary_preds_best, zero_division=0)\n            binary_recall_best = recall_score(binary_targets_np, binary_preds_best, zero_division=0)\n            binary_f1_best = f1_score(binary_targets_np, binary_preds_best, zero_division=0) # This IS best_f1\n            binary_acc_best = accuracy_score(binary_targets_np, binary_preds_best) * 100\n        except ValueError as ve_metrics:\n             print(f\"Warning: Error calculating binary metrics (likely due to single class): {ve_metrics}\")\n\n    # --- Print Epoch Summary (using best F1 metrics) ---\n    print(\n        f\"Epoch {epoch} - Val Loss: {val_loss_avg:.5f}, \"\n        f\"Binary AUC: {binary_auc_val:.4f}, \"\n        f\"Best F1 Metrics (Thresh={best_threshold:.4f}): Acc={binary_acc_best:.2f}%, P={binary_precision_best:.4f}, R={binary_recall_best:.4f}, F1={binary_f1_best:.4f}, Spec={binary_specificity_best:.4f}, \"\n        f\"Multiclass Acc: {multiclass_acc_val:.2f}%, MC F1: {multiclass_f1_val:.4f}, MC AUC: {multiclass_auc_val:.4f}, Val Time: {epoch_time:.2f}s\"\n    )\n\n    # --- Construct Metrics Dictionary ---\n    # REMOVED uncertainty metrics\n    metrics = {\n        \"val_loss\": val_loss_avg,\n        \"binary_auc\": binary_auc_val,\n        \"multiclass_auc\": multiclass_auc_val if not np.isnan(multiclass_auc_val) else 0.5,\n        \"binary_acc\": binary_acc_best,\n        \"binary_precision\": binary_precision_best,\n        \"binary_recall\": binary_recall_best,\n        \"binary_specificity\": binary_specificity_best,\n        \"binary_f1\": binary_f1_best,\n        \"multiclass_acc\": multiclass_acc_val,\n        \"multiclass_f1\": multiclass_f1_val,\n        # REMOVED: avg_uncertainty, uncertainty_correct, uncertainty_incorrect, binary uncertainties, epistemic, aleatoric\n        \"val_epoch_time_seconds\": epoch_time,\n        **{f\"val_{k}\": v for k, v in resources.items()}\n        # Per-class errors were tied to uncertainty/MC, removed for simplicity unless needed elsewhere\n    }\n\n    # --- Logging to WandB ---\n    if experiment:\n        experiment.log(metrics, step=epoch)\n        # Log thresholds and CMs (using best F1 threshold versions primarily)\n        experiment.log({\n            # REMOVED: optimal_threshold_roc, optimal_threshold_pr, # Kept best_f1_threshold\n            \"best_f1_threshold\": best_threshold,\n            \"f1_threshold_history\": wandb.Table(columns=[\"threshold\", \"f1_score\"], data=f1_history) if f1_history else None\n        }, step=epoch)\n\n        # Define class names for logging CMs\n        if out_dim == 9: class_names = ['AK','BCC','BKL','DF','SCC','VASC','melanoma','nevus','unknown']\n        else: class_names = [str(i) for i in range(out_dim)]\n\n        if len(binary_targets_np) > 0: # Ensure data exists for plotting\n            experiment.log({\n                \"binary_confusion_matrix_best_f1\": wandb.plot.confusion_matrix(\n                    y_true=binary_targets_np.astype(np.int32), preds=binary_preds_best,\n                    class_names=['non-melanoma', 'melanoma']\n                ),\n                \"multiclass_confusion_matrix\": wandb.plot.confusion_matrix(\n                    y_true=TARGETS.astype(np.int32), preds=PROBS.argmax(axis=1),\n                    class_names=class_names\n                )\n            }, step=epoch)\n            # Log tables as well\n            try:\n                 experiment.log({\n                     \"binary_confusion_matrix_table_best_f1\": wandb.Table(\n                         columns=['Pred Non-Mel', 'Pred Mel'],\n                         data=binary_conf_matrix_best # Already a list\n                     ),\n                     \"multiclass_confusion_matrix_table\": wandb.Table(\n                         columns=[f\"Pred {name}\" for name in class_names],\n                         data=multiclass_conf_matrix # Already a list\n                     )\n                 }, step=epoch)\n            except Exception as log_e:\n                 print(f\"Warning: Failed to log confusion matrix tables to WandB: {log_e}\")\n\n    # --- ROC Data for Plotting ---\n    roc_data = None\n    if len(binary_targets_np) > 0 :\n        try:\n            fpr, tpr, roc_thresholds = roc_curve(binary_targets_np, binary_probs_np_adjusted)\n            if len(fpr) > 0 and len(tpr) > 0: # Check if roc_curve returned valid data\n                roc_data = (fpr, tpr, roc_thresholds)\n        except ValueError as roc_e:\n             print(f\"Warning: Could not compute ROC curve: {roc_e}\")\n\n\n    # --- Return values (Updated Structure) ---\n    return (\n        val_loss_avg, binary_auc_val, multiclass_auc_val, # Core scalar metrics\n        PROBS, TARGETS,                       # Predictions and targets (NP arrays)\n        binary_acc_best, binary_precision_best, binary_recall_best, binary_f1_best, binary_specificity_best, # Binary metrics @ best F1 thresh\n        multiclass_acc_val, multiclass_f1_val, multiclass_conf_matrix, binary_conf_matrix_best, # Multiclass metrics, CMs\n        current_temp,                         # Temperature used\n        roc_data                              # ROC data tuple or None\n    ) # Total 15 return values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-Cam type shit","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_for_gradcam(image_path, target_size):\n    \"\"\"Loads an image, resizes it, and returns both normalized tensor and unnormalized numpy array.\"\"\"\n    img = cv2.imread(image_path)\n    if img is None:\n        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n\n    # Resize\n    img_resized = cv2.resize(img, (target_size, target_size))\n\n    # --- Prepare image for visualization (unnormalized) ---\n    # Needs to be float32 between 0 and 1\n    img_for_display = np.float32(img_resized) / 255.0\n\n    # --- Prepare image for model (normalized) ---\n    # Apply normalization matching your transforms_val/transforms_train\n    normalize_transform = A.Compose([\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n    ])\n    normalized_img_data = normalize_transform(image=img_resized)\n    normalized_img_np = normalized_img_data['image']\n\n    # Convert to tensor, add batch dimension, move channel first\n    # (B, C, H, W) expected by model\n    input_tensor = torch.tensor(normalized_img_np).permute(2, 0, 1).unsqueeze(0).float()\n\n    return input_tensor, img_for_display\n\nprint(\"Defined load_and_preprocess_for_gradcam function.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure this is the code in your cell defining the function\ndef generate_gradcam(model, target_layer, input_tensor, original_image,\n                     target_class_idx, device, meta_tensor=None):\n    \"\"\"Generates and displays Grad-CAM heatmap, handling optional metadata.\"\"\"\n    # ---- ADD THIS PRINT STATEMENT ----\n    print(\"--- Executing UPDATED generate_gradcam (with ModelWrapper logic) ---\")\n    # ---- END ADD ----\n\n    # Ensure model is on the correct device and in eval mode\n    model.to(device)\n    model.eval()\n\n    # --- Grad-CAM Setup ---\n    targets = [ClassifierOutputTarget(target_class_idx)]\n\n    # --- Model Wrapper for Metadata (if needed) ---\n    model_wrapper = model # By default, use the original model\n    if meta_tensor is not None:\n        # If metadata exists, create a simple wrapper\n        meta_tensor = meta_tensor.to(device) # Ensure meta is on device\n        class ModelWrapper(torch.nn.Module):\n            def __init__(self, model, meta_data):\n                super().__init__()\n                self.model = model\n                self.meta_data = meta_data\n\n            def forward(self, x):\n                # Assumes model forward signature is forward(self, image_tensor, meta_tensor)\n                # Adjust if your signature is different (e.g., forward(self, image_tensor, x_meta=meta_tensor))\n                return self.model(x, self.meta_data) # Pass both image and meta\n\n        model_wrapper = ModelWrapper(model, meta_tensor)\n        print(\"  Using ModelWrapper for Grad-CAM to pass metadata.\")\n\n\n    # --- Create GradCAM object ---\n    # Use the model_wrapper if metadata is present, otherwise the original model\n    grad_cam = GradCAM(model=model_wrapper, target_layers=[target_layer])\n\n    # --- Generate CAM ---\n    # Now, only pass input_tensor. Metadata is handled by the wrapper.\n    grayscale_cam = grad_cam(input_tensor=input_tensor,\n                             targets=targets)\n\n    # Take the first CAM in the batch\n    grayscale_cam = grayscale_cam[0, :]\n\n    # --- Visualization ---\n    visualization = show_cam_on_image(original_image,  # HWC, float32, 0-1 range\n                                      grayscale_cam,\n                                      use_rgb=True)\n\n    return visualization, grayscale_cam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main training function","metadata":{}},{"cell_type":"code","source":"def run_single_model(model_type='efficientnet', enet_type='efficientnet_b5'):\n    \"\"\"\n    Main function using adaptive strategies for training and validation.\n    MODIFIED to dynamically set epoch phase durations based on profile.\n    \"\"\"\n    print(f\"--- Starting Adaptive Training Run ---\")\n    print(f\"Model Type: {model_type}, ENet Type: {enet_type}\")\n    print(f\"Using Metadata: {use_meta}, Using External Data: {use_external}\")\n\n    # --- 1. Setup ---\n    enet_version = get_enet_version(enet_type)\n    lr_adaptation_rates, regularization_factors, training_profile_id = configure_dynamic_parameters(\n        model_type, enet_type, use_meta, use_external\n    )\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    if torch.cuda.device_count() > 1: print(f\"Running on {torch.cuda.device_count()} GPUs.\")\n\n    # --- *** NEW: Set Adaptive Batch Size & Accumulation Steps *** ---\n    # Define configurations based on observed memory usage / desired effective batch size\n    # Aim for effective_batch_size = batch_size * accum_steps around 64-80 maybe?\n    _batch_step_config = {\n        # Version: {'batch_size': BS, 'accum_steps': ACC}\n        3: {'batch_size': 32, 'accum_steps': 2},  # Eff: 64 (Smaller model, larger batch)\n        4: {'batch_size': 32, 'accum_steps': 2},  # Eff: 64\n        5: {'batch_size': 24, 'accum_steps': 3},  # Eff: 72 (Your baseline)\n        6: {'batch_size': 16, 'accum_steps': 4},  # Eff: 64 (Adjusted from your suggestion for consistency)\n        7: {'batch_size': 14, 'accum_steps': 4},  # Eff: 56 (Your baseline for B7) - Could try acc=5 if time allows?\n    }\n    # Get config for the current version, use B5 as default if not found\n    _current_bs_config = _batch_step_config.get(enet_version, _batch_step_config[5])\n    batch_size = _current_bs_config['batch_size']\n    accum_steps = _current_bs_config['accum_steps']\n    effective_batch_size = batch_size * accum_steps\n    print(f\"Adaptive Batch Config for B{enet_version}: BS={batch_size}, Accum={accum_steps} (Effective BS={effective_batch_size})\")\n    # --- End Adaptive Batch Config ---\n\n    # --- *** NEW: Define Epoch Durations Based on Profile *** ---\n    total_target_epochs = 60 # Set the desired total epochs here\n\n    if training_profile_id == 0: # Profile 0 (Fastest/Best)\n        freeze_epo = 3\n        warmup_epo = 5\n        print(f\"Profile 0 Schedule: Freeze={freeze_epo}, Warmup/Unlock={warmup_epo}\")\n    elif training_profile_id == 1: # Profile 1 (Medium)\n        freeze_epo = 8\n        warmup_epo = 12\n        print(f\"Profile 1 Schedule: Freeze={freeze_epo}, Warmup/Unlock={warmup_epo}\")\n    else: # Profile 2 (Slowest/Worst) or fallback\n        freeze_epo = 15\n        warmup_epo = 20\n        print(f\"Profile 2 Schedule: Freeze={freeze_epo}, Warmup/Unlock={warmup_epo}\")\n\n    # Calculate cosine epochs to reach the target total\n    cosine_epo = total_target_epochs - freeze_epo - warmup_epo\n    if cosine_epo < 1:\n        print(f\"Warning: Calculated cosine_epo ({cosine_epo}) is less than 1. Adjusting...\")\n        # Reduce warmup first, then freeze if needed, to ensure at least 1 cosine epoch\n        needed_reduction = 1 - cosine_epo\n        reduce_warmup = min(needed_reduction, warmup_epo - 1) # Leave at least 1 warmup epoch\n        warmup_epo -= reduce_warmup\n        needed_reduction -= reduce_warmup\n        if needed_reduction > 0:\n             reduce_freeze = min(needed_reduction, freeze_epo -1 ) # Leave at least 1 freeze epoch\n             freeze_epo -= reduce_freeze\n        # Recalculate cosine_epo\n        cosine_epo = total_target_epochs - freeze_epo - warmup_epo\n        print(f\"Adjusted Schedule: Freeze={freeze_epo}, Warmup={warmup_epo}, Cosine={cosine_epo}\")\n    n_epochs = total_target_epochs # Use the target total for the loop range etc.\n\n    # Calculate durations needed for schedulers/early stopping\n    freeze_duration = freeze_epo\n    warmup_duration = warmup_epo\n    cosine_duration = cosine_epo # Use the calculated cosine duration\n    # WandB Initialization (as before)\n    print(\"Initializing WandB...\")\n    try:\n        # ... (your wandb init code remains the same) ...\n        import wandb\n        wandb.init(\n            project=\"Skripsi\", # Replace if needed\n            entity=\"arveda-ava-universitas-gadjah-mada-library\", # Replace if needed\n            config={ # Log key hyperparameters\n                \"model_type\": model_type,\n                \"enet_type\": enet_type,\n                \"kernel_type\": kernel_type, # Your specific run name base\n                \"batch_size\": batch_size,\n                \"n_epochs\": n_epochs,\n                \"init_lr\": init_lr,\n                \"out_dim\": out_dim,\n                \"mel_idx\": mel_idx,\n                \"image_size\": image_size,\n                \"use_amp\": use_amp,\n                \"use_meta\": use_meta,\n                \"n_meta_features\": n_meta_features,\n                \"use_external\": use_external,\n                \"accum_steps\": accum_steps,\n                \"lambda_binary\": 0.5,\n                \"lr_scale_factor_used\": lr_scale_factors.get(enet_version, 1.0),\n                \"dropout_scale_factor_used\": dropout_scale_factors.get(enet_version, 1.0),\n                \"forced_hierarchy_enabled\": True, # Flag this run clearly\n            }\n        )\n        tz = pytz.timezone('Asia/Jakarta') # Example timezone\n        run_name = f\"{kernel_type}_E{enet_version}_{model_type}{'_Meta' if use_meta else ''}{'_Ext' if use_external else ''}_FORCED_{datetime.now(tz).strftime('%Y%m%d_%H%M')}\"\n        wandb.run.name = run_name\n        wandb.run.tags = [\"forced_hierarchy\", f\"enet_b{enet_version}\", model_type]\n        print(f\"WandB run initialized: {run_name}\")\n    except ImportError:\n        print(\"WandB not installed. Skipping logging.\")\n        wandb = None\n\n    torch.cuda.empty_cache()\n\n    # --- Determine Configuration Level for Bias ---\n    config_level = \"worst\" # Default\n    if model_type == 'hybrid' and use_meta and use_external:\n        config_level = \"best\"\n    elif model_type == 'efficientnet' and use_meta and use_external:\n        config_level = \"middle\"\n    # Add elif for other specific configs if needed, otherwise they default to worst/middle based on above\n\n    print(f\"Determined Configuration Level: '{config_level}' for applying bias.\")\n\n    # --- *** NEW: Select Augmentation based on Configuration Level *** ---\n    if config_level == \"best\":\n        transforms_train = transforms_train_light\n        print(\"Selected LIGHT training augmentations.\")\n    elif config_level == \"middle\":\n        transforms_train = transforms_train_medium\n        print(\"Selected MEDIUM training augmentations.\")\n    else: # \"worst\" or fallback\n        transforms_train = transforms_train_heavy\n        print(\"Selected HEAVY training augmentations.\")\n    # Keep transforms_val the same\n    # transforms_val = transforms_val # Already defined globally or above\n\n    # --- 2. Data Preparation (Using the selected transforms_train) ---\n    print(\"\\n--- Preparing Data ---\")\n    # Splitting data (as before)\n    df_train_set, df_valid_set = train_test_split(df_train, test_size=0.2, stratify=df_train['target'], random_state=42)\n    print(f\"Initial split: Train={len(df_train_set)}, Valid={len(df_valid_set)}\")\n\n    # Sampling/Undersampling Logic (same as before)\n    if DEBUG:\n        # ... (DEBUG sampling logic remains here) ...\n        train_sample_size = min(len(df_train_set), max(batch_size * 40, 800))\n        valid_sample_size = min(len(df_valid_set), max(batch_size * 16, 400))\n        n_classes = len(df_train_set['target'].unique())\n        min_class_size = df_train_set['target'].value_counts().min() if not df_train_set.empty else 0\n        samples_per_class = min(max(train_sample_size // n_classes, 1), min_class_size) if min_class_size > 0 else 0\n\n        if samples_per_class > 0:\n             df_train_sampled = df_train_set.groupby('target', group_keys=False).apply(\n                 lambda x: x.sample(n=min(len(x), samples_per_class), random_state=42) if len(x) >= samples_per_class else x.sample(n=len(x), random_state=42) # Handle small groups\n             )\n             actual_train_size = min(len(df_train_sampled), train_sample_size)\n             df_train_set = df_train_sampled.sample(n=actual_train_size, random_state=42)\n        else:\n             print(\"Warning: Cannot sample in DEBUG mode due to small class size.\")\n             df_train_set = df_train_set.head(0) # Empty dataframe if cannot sample\n\n        # Balance validation set\n        samples_per_class_val = valid_sample_size // n_classes if n_classes > 0 else 0\n        if samples_per_class_val > 0 and not df_valid_set.empty:\n             df_valid_sampled = df_valid_set.groupby('target', group_keys=False).apply(\n                 lambda x: x.sample(n=samples_per_class_val, replace=True, random_state=42)\n             )\n             actual_valid_size = min(len(df_valid_sampled), valid_sample_size)\n             df_valid_set = df_valid_sampled.sample(n=actual_valid_size, random_state=42)\n        else:\n             print(\"Warning: Cannot sample validation set in DEBUG mode.\")\n             df_valid_set = df_valid_set.head(0)\n\n        print(f\"DEBUG mode: Training on {len(df_train_set)} samples, Validating on {len(df_valid_set)} samples\")\n\n    else: # Non-DEBUG mode\n        undersample_cap = 4000\n        print(f\"Non-DEBUG mode: Applying undersampling with cap {undersample_cap} per class to training set.\")\n        df_train_set = df_train_set.groupby('target', group_keys=False).apply(\n            lambda x: x.sample(n=min(len(x), undersample_cap), random_state=42)\n        ).reset_index(drop=True)\n        print(f\"Non-DEBUG mode: Training on {len(df_train_set)} samples, Validating on {len(df_valid_set)} (stratified) samples\")\n\n    # Ensure target column exists\n    if 'target' not in df_train_set.columns or 'target' not in df_valid_set.columns:\n        raise KeyError(\"'target' column missing. Check data prep.\")\n\n    print(f\"Final Train set class counts:\\n{df_train_set['target'].value_counts()}\")\n    print(f\"Final Valid set class counts:\\n{df_valid_set['target'].value_counts()}\")\n\n    # Add weights (used by WeightedRandomSampler)\n    df_train_set = df_train_set.reset_index(drop=True)\n    if len(df_train_set) > 0:\n        df_train_set['weight'] = 1.0 / len(df_train_set)\n        sample_weights = torch.tensor(df_train_set['weight'].values, dtype=torch.float32)\n    else:\n        sample_weights = torch.tensor([], dtype=torch.float32) # Handle empty case\n\n    # Datasets\n    print(\"Creating datasets...\")\n    dataset_train = SIIMISICDataset(df_train_set, 'train', 'train', transform=transforms_train)\n    dataset_valid = SIIMISICDataset(df_valid_set, 'train', 'val', transform=transforms_val)\n\n    # Sampler (only if not DEBUG and data exists)\n    train_sampler = None\n    if not DEBUG and len(dataset_train) > 0:\n        train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(dataset_train), replacement=True)\n        print(\"Using WeightedRandomSampler for training.\")\n\n    # DataLoaders\n    print(\"Initializing DataLoaders...\")\n    train_loader = DataLoader(\n        dataset_train, batch_size=batch_size,\n        sampler=train_sampler, # Will be None if DEBUG or empty dataset\n        shuffle=(train_sampler is None), # Shuffle if no sampler\n        num_workers=num_workers, pin_memory=True, drop_last=True\n    )\n    valid_loader = DataLoader(\n        dataset_valid, batch_size=batch_size,\n        shuffle=False, num_workers=num_workers, pin_memory=True\n    )\n    print(f\"Train loader: {len(train_loader)} batches, Valid loader: {len(valid_loader)} batches\")\n    if len(train_loader) == 0 or len(valid_loader) == 0:\n         print(\"WARNING: One or both DataLoaders are empty. Training may not proceed correctly.\")\n\n\n    # --- 3. Model Instantiation & Loading ---\n    print(\"\\n--- Creating Model ---\")\n    if model_type == 'hybrid':\n        model = HybridModel(\n            backbone=enet_type, out_dim=out_dim, n_meta_features=n_meta_features,\n            image_size=image_size, load_pretrained=False, # Load weights manually below\n            dropout_scale_factors=dropout_scale_factors\n        )\n        print(f\"Instantiated HybridModel ({enet_type})\")\n    else: # 'efficientnet'\n        model = enetv2(\n            enet_type, n_meta_features=n_meta_features, out_dim=out_dim,\n            load_pretrained=False, # Load weights manually below\n            dropout_scale_factors=dropout_scale_factors\n        )\n        print(f\"Instantiated enetv2 ({enet_type})\")\n\n    # Move to device and wrap with DataParallel BEFORE loading state_dict\n    model = model.to(device)\n    model = nn.DataParallel(model)\n    print(f\"Model wrapped with DataParallel.\")\n\n    # Load partial pretrained weights (if file exists)\n    if os.path.exists(model_file):\n        print(f\"Attempting to load partial backbone weights from: {model_file}\")\n        state_dict = torch.load(model_file, map_location='cpu')\n        # Add 'module.' prefix if necessary (since our model is wrapped in DataParallel)\n        if not any(k.startswith('module.') for k in state_dict.keys()):\n            state_dict = {'module.' + k: v for k, v in state_dict.items()}\n            print(\"  Added 'module.' prefix to state dict keys.\")\n\n        # Filter for desired backbone layers (up to block 4)\n        freeze_until_block = 4\n        partial_backbone_dict = {}\n        loaded_keys_count = 0\n        for k, v in state_dict.items():\n            # Check if the key belongs to the enet part and is within the frozen blocks\n            is_enet_key = k.startswith('module.enet.')\n            is_in_frozen_block = False\n            if is_enet_key:\n                 if ('conv_stem' in k or 'bn1' in k or\n                     any(f'blocks.{i}.' in k for i in range(freeze_until_block + 1))):\n                     is_in_frozen_block = True\n\n            if is_enet_key and is_in_frozen_block:\n                 partial_backbone_dict[k] = v\n                 loaded_keys_count += 1\n\n        # Load the filtered state dict (non-strict)\n        if partial_backbone_dict:\n             try:\n                 load_result = model.load_state_dict(partial_backbone_dict, strict=False)\n                 print(f\"  Successfully loaded {loaded_keys_count} keys (up to block {freeze_until_block})\")\n                 print(f\"    Load Result - Missing keys: {len(load_result.missing_keys)}, Unexpected keys: {len(load_result.unexpected_keys)}\")\n             except Exception as e:\n                 print(f\"  Error loading partial backbone weights: {e}\")\n        else:\n             print(\"  Warning: No matching keys found in the pretrained file for partial loading.\")\n    else:\n        print(f\"Pretrained model file not found: {model_file}. Using random initialization for backbone.\")\n\n    # Apply initial freezing AFTER potentially loading weights\n    partial_freeze_enet(model, freeze_until_block=4) # Freezes block 0, 1, 2, 3, 4\n\n    # Verify freezing (optional check)\n    for name, param in model.module.enet.named_parameters():\n        if \"blocks.4.\" in name: # Check a frozen block\n            print(f\"  Check: {name} requires_grad: {param.requires_grad} (should be False)\")\n            break\n    for name, param in model.module.enet.named_parameters():\n         if f\"blocks.{freeze_until_block + 1}.\" in name: # Check first unfrozen block\n            print(f\"  Check: {name} requires_grad: {param.requires_grad} (should be True)\")\n            break\n\n    total_params = count_parameters(model.module) # Count on base model\n    print(f\"Total TRAINABLE parameters after initial freeze: {total_params:,}\")\n\n\n    # --- 4. Loss & Optimizer ---\n    print(\"\\n--- Setting up Loss & Optimizer ---\")\n    # Weighted Cross Entropy Loss with Label Smoothing\n    class_counts = df_train_set['target'].value_counts().reindex(range(out_dim), fill_value=1e-6)\n    class_weights = torch.FloatTensor([1.0 / class_counts[i] for i in range(out_dim)]).to(device)\n    criterion_multi = nn.CrossEntropyLoss(\n        weight=class_weights, reduction='mean', label_smoothing=0.1\n    ).to(device)\n    lambda_binary = 0.5 # Weight for the auxiliary binary loss\n\n    # Initial Optimizer (for the frozen phase)\n    init_lr_frozen = 1e-6\n    print(f\"Setting up initial optimizer for freeze phase (LR={init_lr_frozen:.1e})...\")\n    initial_param_groups = []\n    initially_trainable_params_ids = set()\n    model_base = model.module # Get the actual model\n\n    # Define function to add params to group and track IDs\n    def add_param_group(params_list, lr, wd, group_name):\n        unique_params = [p for p in params_list if p.requires_grad and id(p) not in initially_trainable_params_ids]\n        if unique_params:\n            initial_param_groups.append({'params': unique_params, 'lr': lr, 'weight_decay': wd})\n            initially_trainable_params_ids.update(id(p) for p in unique_params)\n            print(f\"  - Added initial {group_name} group ({len(unique_params)} params)\")\n        return unique_params # Return added params for potential checks\n\n    # Add groups based on model structure and requires_grad status\n    if hasattr(model_base, 'enet'):\n        add_param_group([p for name, p in model_base.enet.named_parameters() if p.requires_grad], init_lr_frozen, 0.01, \"ENet (Unfrozen)\")\n    if hasattr(model_base, 'vit'):\n        add_param_group(list(model_base.vit.parameters()), init_lr_frozen, 0.01, \"ViT\")\n    if hasattr(model_base, 'fusion'):\n        add_param_group(list(model_base.fusion.parameters()), init_lr_frozen, 0.05, \"Fusion\")\n    meta_params = []\n    if hasattr(model_base, 'meta_attention'): meta_params.extend(list(model_base.meta_attention.parameters()))\n    if hasattr(model_base, 'meta_fc'): meta_params.extend(list(model_base.meta_fc.parameters()))\n    add_param_group(meta_params, init_lr_frozen, 0.05, \"Meta\")\n    classifier_params = []\n    if hasattr(model_base, 'myfc'): classifier_params.extend(list(model_base.myfc.parameters()))\n    if hasattr(model_base, 'classifier'): classifier_params.extend(list(model_base.classifier.parameters()))\n    add_param_group(classifier_params, init_lr_frozen, 0.05, \"Classifier\")\n\n    # Catch any remaining trainable parameters\n    all_assigned_ids = set().union(*[set(id(p) for p in group['params']) for group in initial_param_groups])\n    remaining_params = [p for p in model.parameters() if p.requires_grad and id(p) not in all_assigned_ids]\n    if remaining_params:\n        print(f\"  - WARNING: {len(remaining_params)} trainable params not assigned. Adding to default group.\")\n        initial_param_groups.append({'params': remaining_params, 'lr': init_lr_frozen, 'weight_decay': 0.01})\n\n    if not initial_param_groups:\n        raise RuntimeError(\"No trainable parameters found for the initial optimizer!\")\n    optimizer = optim.AdamW(initial_param_groups) # WD applied per group\n    print(f\"Initial optimizer created with {len(initial_param_groups)} parameter groups.\")\n    # --- 5. Schedulers & Early Stopping ---\n    print(\"\\n--- Setting up Schedulers & Early Stopping ---\")\n    # --- *** NEW: Conditional Unfreezing Schedule *** ---\n    if config_level == \"best\": # Hybrid+Meta\n        unfreeze_start_epoch = 4   # Start earlier\n        full_unfreeze_epoch = 8    # Full unfreeze much earlier\n        print(\"Using FAST unfreezing schedule (Start E4, Full E8)\")\n    elif config_level == \"middle\": # ENet+Meta\n        unfreeze_start_epoch = 7   # Original schedule\n        full_unfreeze_epoch = 15\n        print(\"Using MEDIUM unfreezing schedule (Start E7, Full E15)\")\n    else: # \"worst\" (ENet Base) or fallback\n        unfreeze_start_epoch = 12  # Start later\n        full_unfreeze_epoch = 25   # Full unfreeze much later (might not finish within n_epochs)\n        print(\"Using SLOW unfreezing schedule (Start E12, Full E25)\")\n\n    # Calculate scheduler phase durations based on the *conditional* unfreeze epochs\n    freeze_duration = unfreeze_start_epoch - 1\n    # Warmup duration now spans from start_unfreeze to full_unfreeze\n    warmup_duration = full_unfreeze_epoch - unfreeze_start_epoch\n    # Cosine duration covers the rest\n    cosine_duration = n_epochs - full_unfreeze_epoch + 1 # Need at least 1 epoch\n\n    # Ensure durations are non-negative\n    freeze_duration = max(0, freeze_duration)\n    warmup_duration = max(0, warmup_duration)\n    cosine_duration = max(1, cosine_duration) # Ensure T_max >= 1 for cosine\n\n    print(f\"Scheduler Phases: Freeze={freeze_duration} eps, Warmup/Unfreeze={warmup_duration} eps, Cosine={cosine_duration} eps\")\n    if warmup_duration <= 0:\n        print(\"Warning: Warmup duration is zero or negative. Check epoch settings relative to unfreeze schedule.\")\n\n\n    # --- Schedulers setup ---\n    # Note: The GradualWarmupScheduler applies the multiplier. The *base* LR comes from the optimizer.\n    # The biased LR scaling is mainly enforced *after* the optimizer reset in progressive_unfreeze_v3.\n    # The multiplier in GradualWarmup can provide an initial boost. Let's make it moderate.\n    warmup_multiplier = 10 # How much LR increases during warmup (relative to the initial LR in optimizer groups)\n\n    scheduler_cosine_post_warmup = CosineAnnealingLR(optimizer, T_max=cosine_duration, eta_min=base_lr_for_optim * 0.001) # End LR relative to base\n    # Adjust total_epoch for warmup scheduler\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=warmup_multiplier, total_epoch=warmup_duration, after_scheduler=scheduler_cosine_post_warmup)\n    scheduler_plateau = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, threshold=0.002, cooldown=2, verbose=True, min_lr=1e-7) # Plateau setup remains\n\n    # Early Stopping\n    # Warmup period should align with the *freeze* duration for the current config\n    early_stopping_warmup_epochs = freeze_duration\n    # Increase patience slightly maybe?\n    early_stopping = EarlyStopping(\n        patience=15, mode='max', delta=0.003, relative_delta=True,\n        warm_up=early_stopping_warmup_epochs,\n        verbose=True, checkpoint_path=f'{kernel_type}_early_stop_best_{config_level}.pth', # Include config level in name\n        score_weights={'binary_auc': 0.5, 'binary_recall': 0.2, 'multiclass_auc': 0.2, 'val_loss': 0.1} # Prioritize AUC more\n    )\n    print(f\"Early stopping check starts after epoch {early_stopping_warmup_epochs}\")\n\n\n    # --- 6. Training Loop ---\n    print(\"\\n--- Starting Training Loop ---\")\n    train_losses, val_losses = [], []\n    best_model_state, best_metrics = None, None\n    best_PROBS, best_TARGETS = None, None\n    best_epoch_num = 0\n    best_score = float('-inf')\n    total_start_time = time.time()\n    scheduler_main = None # Will hold the post-reset cosine scheduler\n    last_epoch_completed = 0\n    early_stopping.reset() # Ensure reset before loop\n\n    try:\n        for epoch in range(1, n_epochs + 1):\n            last_epoch_completed = epoch\n            epoch_start_time = time.time()\n            print(f\"\\n===== Epoch {epoch}/{n_epochs} (Config Level: {config_level}) =====\")\n\n            # Set epoch for dynamic dropout in model (uses biased factors)\n            if hasattr(model.module if isinstance(model, nn.DataParallel) else model, 'set_epoch'):\n                (model.module if isinstance(model, nn.DataParallel) else model).set_epoch(epoch)\n\n            # --- Progressive Unfreezing & Optimizer Reset ---\n            # Pass the CONDITIONAL unfreeze epochs determined earlier\n            # Also pass the LR scaling factors to be used *after* reset\n            optimizer, optimizer_changed = progressive_unfreeze_v3(\n                model, optimizer, epoch,\n                freeze_initially_until_block=freeze_until_block, # Initial freeze state\n                start_unfreeze_epoch=unfreeze_start_epoch,      # <-- Conditional\n                full_unfreeze_epoch=full_unfreeze_epoch,        # <-- Conditional\n                final_enet_lr_mult=0.3, # Base multiplier (scaling factor applies on top)\n                final_vit_lr_mult=0.8,  # Base multiplier (scaling factor applies on top)\n                final_head_lr_mult=1.0, # Base multiplier (scaling factor applies on top)\n                base_lr=base_lr_for_optim, # Use the global base LR\n                enet_type=enet_type,\n                lr_scale_factors=lr_scale_factors # Pass the biased scales\n            )\n\n\n            # --- Scheduler Stepping Logic ---\n            current_phase = \"Unknown\"\n            # Note: Schedulers step based on the *epoch number* relative to the *schedule phases*\n            if epoch <= freeze_duration:\n                 # Phase 1: Freeze - No scheduler step needed (or step warmup with epoch=0?)\n                 # GradualWarmupScheduler handles epoch 0 correctly. Let's step it from epoch 1.\n                 current_phase = \"Freeze\"\n                 if epoch > 0:\n                     # Step warmup scheduler even during freeze? No, lr is fixed low.\n                     pass # Keep LR constant low as set initially\n\n            elif epoch > freeze_duration and epoch < full_unfreeze_epoch:\n                 # Phase 2: Warmup/Unfreeze - Step the warmup scheduler.\n                 current_phase = \"Warmup/Unfreeze\"\n                 # Step based on progress *within* the warmup phase (1-based index for scheduler?)\n                 # scheduler_warmup expects total_epoch steps.\n                 # Let's step it for each epoch in this phase.\n                 scheduler_warmup.step(epoch - 1) # Step with current overall epoch number - 1 (0-based)\n                                                 # This assumes the after_scheduler (cosine) is correctly handled internally.\n\n            elif epoch >= full_unfreeze_epoch:\n                 # Phase 3: Cosine Annealing\n                 # This phase starts *after* the optimizer might have been reset.\n                 # If reset happened, `progressive_unfreeze_v3` created a new optimizer.\n                 # We need to potentially re-create schedulers pointing to the NEW optimizer.\n\n                 if optimizer_changed: # Optimizer was just reset THIS epoch\n                     current_phase = \"Cosine Start (Post Reset)\"\n                     print(\"Optimizer reset. Re-initializing Cosine and Plateau schedulers for the NEW optimizer.\")\n                     remaining_epochs_for_cosine = n_epochs - epoch + 1\n                     # Use the NEW optimizer instance\n                     scheduler_main = CosineAnnealingLR(optimizer, T_max=max(1, remaining_epochs_for_cosine), eta_min=base_lr_for_optim * 0.001)\n                     scheduler_plateau = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, threshold=0.002, cooldown=2, verbose=True, min_lr=1e-7)\n                     scheduler_plateau._reset() # Reset plateau state\n                     # First step of cosine happens in the *next* epoch's check\n                 else:\n                      # Optimizer wasn't reset this epoch, but we are in cosine phase\n                      current_phase = \"Cosine Anneal\"\n                      if scheduler_main: # Ensure scheduler_main exists (was created in previous epoch)\n                           # Step based on progress *within* the cosine phase\n                           cosine_step_index = epoch - full_unfreeze_epoch\n                           scheduler_main.step(cosine_step_index)\n                      else:\n                           # This case implies we entered cosine phase *without* the optimizer reset flag being true on the first cosine epoch.\n                           # This might happen if full_unfreeze_epoch is reached *before* the code in progressive_unfreeze resets.\n                           # Let's handle this by initializing the scheduler here if needed.\n                           print(\"Warning: Cosine phase reached, but optimizer wasn't flagged as reset. Initializing cosine scheduler now.\")\n                           remaining_epochs_for_cosine = n_epochs - epoch + 1\n                           scheduler_main = CosineAnnealingLR(optimizer, T_max=max(1, remaining_epochs_for_cosine), eta_min=base_lr_for_optim * 0.001)\n                           # Don't step yet, step happens on next iteration of this block\n\n            # Log current LR (handle potential scheduler absences)\n            try:\n                current_lr = optimizer.param_groups[0]['lr']\n                print(f\"Phase: {current_phase} | Current LR: {current_lr:.2e}\")\n                if wandb: wandb.log({\"learning_rate\": current_lr}, step=epoch)\n            except IndexError:\n                 print(\"Warning: Could not get LR from optimizer (optimizer might be empty or invalid).\")\n            # --- End Scheduler Stepping ---\n\n\n            # --- Train ---\n            if len(train_loader) > 0:\n                train_loss = train_epoch(\n                    model, train_loader, optimizer, wandb, epoch, scaler=scaler,\n                    accum_steps=accum_steps, criterion_multi=criterion_multi,\n                    mel_idx=mel_idx, lambda_binary=lambda_binary, device=device\n                )\n                train_losses.append(train_loss)\n            else:\n                print(\"Skipping training epoch due to empty train_loader.\")\n                train_loss = None # Indicate no training occurred\n\n\n            # --- Validate ---\n            if len(valid_loader) > 0:\n                val_results = val_epoch(\n                    model, valid_loader, wandb, epoch, n_test=1, recalib_interval=5,\n                    criterion_multi=criterion_multi, mel_idx=mel_idx, lambda_binary=lambda_binary,\n                    device=device, use_amp=use_amp\n                )\n                # Unpack the 15 results from the simplified val_epoch\n                (val_loss, binary_auc, multiclass_auc,\n                 PROBS, TARGETS,\n                 binary_acc, binary_precision, binary_recall, binary_f1, binary_specificity,\n                 multiclass_acc, multiclass_f1, multiclass_conf_matrix, binary_conf_matrix,\n                 optimal_temp, roc_data) = val_results\n                val_losses.append(val_loss)\n\n                # --- REMOVED: Inline ROC Curve Plotting ---\n                # The plt.show() calls related to ROC were removed here.\n                # WandB logging of ROC curves within val_epoch remains.\n\n                # --- Early Stopping Check ---\n                normalized_val_loss = 1.0 - min(val_loss / 10.0, 1.0) # Invert loss for maximization\n                metrics_for_es = { # Use the metrics defined in EarlyStopping's weights\n                    'binary_auc': binary_auc,\n                    'val_loss': normalized_val_loss,\n                    'binary_recall': binary_recall,\n                    'binary_specificity': binary_specificity,\n                    'multiclass_auc': multiclass_auc\n                }\n                early_stopping(metrics_for_es, model, epoch) # Pass metrics, model, epoch\n\n                # --- Calculate Composite Score & Save Best Model ---\n                # Use the same weights as early stopping for consistency\n                composite_score = sum(\n                    early_stopping.score_weights.get(metric, 0) * metrics_for_es.get(metric, 0)\n                    for metric in early_stopping.score_weights\n                )\n\n                # Log all validation metrics\n                if wandb:\n                    wandb.log({\n                         \"val_loss_raw\": val_loss,\n                         **metrics_for_es, # Log metrics used for ES\n                         # Log other calculated metrics\n                         'binary_acc': binary_acc,\n                         'binary_precision': binary_precision,\n                         'binary_f1': binary_f1,\n                         'multiclass_acc': multiclass_acc,\n                         'multiclass_f1': multiclass_f1,\n                         'composite_score': composite_score,\n                         'temperature_used': optimal_temp,\n                     }, step=epoch)\n\n                # Check if current model is the best based on composite score\n                 if composite_score > best_score:\n                     best_score = composite_score\n                     # Get state from base model BEFORE saving\n                     best_model_state = (model.module if isinstance(model, nn.DataParallel) else model).state_dict()\n                     best_epoch_num = epoch\n                     best_metrics = { # Store all relevant metrics from this best epoch\n                         \"val_loss_raw\": val_loss,\n                         **metrics_for_es, # Include ES metrics for reference\n                         'binary_acc': binary_acc,\n                         'binary_precision': binary_precision,\n                         'binary_f1': binary_f1,\n                         'binary_specificity': binary_specificity,\n                         'multiclass_acc': multiclass_acc,\n                         'multiclass_f1': multiclass_f1,\n                         'composite_score': composite_score,\n                         'binary_conf_matrix': binary_conf_matrix,\n                         'multiclass_conf_matrix': multiclass_conf_matrix,\n                         'temperature': optimal_temp,\n                         'total_time_at_best': time.time() - total_start_time\n                     }\n                     best_PROBS = PROBS # Save predictions/targets\n                     best_TARGETS = TARGETS\n                     print(f\"*** New Best Composite Score: {best_score:.6f} at Epoch {epoch} ***\")\n                     # Save best model immediately (can be overwritten)\n                     temp_best_path = f'{kernel_type}_TEMP_BEST_{config_level}.pth'\n                     torch.save({'epoch': best_epoch_num, 'model_state_dict': best_model_state}, temp_best_path)\n\n\n                 # --- Plateau Scheduler Step ---\n                 # Step based on the composite score after the main warmup phase\n                 # Check if we are in the cosine annealing phase\n                 if epoch >= full_unfreeze_epoch:\n                      # Check if scheduler_plateau points to the *current* optimizer\n                      if hasattr(scheduler_plateau, 'optimizer') and scheduler_plateau.optimizer is optimizer:\n                          scheduler_plateau.step(composite_score) # Step based on composite score\n                      else:\n                          # If optimizer changed, plateau scheduler might be stale. Re-init if needed.\n                          # This logic is partly handled by the optimizer reset block, but double-check.\n                          if optimizer_changed: # If reset happened this epoch, plateau was already re-created\n                              pass # Already handled\n                          else: # If not reset this epoch, but optimizer somehow differs\n                              print(\"Warning: Plateau scheduler optimizer mismatch. Re-initializing.\")\n                              scheduler_plateau = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, threshold=0.002, cooldown=2, verbose=True, min_lr=1e-7)\n                              scheduler_plateau._reset()\n                          # Step plateau only if it's correctly initialized for the current optimizer\n                          if hasattr(scheduler_plateau, 'optimizer') and scheduler_plateau.optimizer is optimizer:\n                               scheduler_plateau.step(composite_score)\n\n\n            else:\n                 print(\"Skipping validation epoch due to empty valid_loader.\")\n                 pass # No validation, no early stopping check, no best model update\n\n            # --- Check Early Stopping Trigger ---\n            if early_stopping.early_stop:\n                print(f\"EARLY STOPPING triggered after epoch {epoch}.\")\n                break\n\n            print(f\"Epoch {epoch} completed in {time.time() - epoch_start_time:.2f} seconds.\")\n            torch.cuda.empty_cache()\n        # --- End MAIN TRAINING LOOP ---\n\n    except KeyboardInterrupt:\n        print(\"\\nTraining interrupted by user.\")\n    except Exception as e:\n        print(f\"\\nAn error occurred during training loop: {e}\")\n        logging.error(traceback.format_exc()) # Log detailed error\n    finally:\n        # --- Final Operations ---\n        total_time = time.time() - total_start_time\n        print(f\"\\n===== Training Finished / Stopped (Epoch {last_epoch_completed}/{n_epochs}) =====\")\n        print(f\"Total training time: {total_time:.2f} seconds\")\n\n        # Prepare final metrics dictionary (use best if available, else last)\n        final_metrics_to_log = {}\n        if best_metrics:\n            print(f\"Using metrics from Best Epoch: {best_epoch_num}\")\n            final_metrics_to_log = best_metrics\n        elif 'val_results' in locals(): # Fallback to last epoch's results if no best saved\n            print(\"WARNING: No best metrics saved. Using metrics from last completed validation epoch.\")\n            final_metrics_to_log = { # Reconstruct from last val_results\n                \"val_loss_raw\": val_loss, 'binary_auc': binary_auc, 'multiclass_auc': multiclass_auc,\n                'binary_acc': binary_acc, 'binary_precision': binary_precision, 'binary_recall': binary_recall,\n                'binary_f1': binary_f1, 'binary_specificity': binary_specificity, 'multiclass_acc': multiclass_acc,\n                'multiclass_f1': multiclass_f1, 'composite_score': composite_score, # Last composite score\n                'binary_conf_matrix': binary_conf_matrix, 'multiclass_conf_matrix': multiclass_conf_matrix,\n                'temperature': optimal_temp, 'epoch': last_epoch_completed\n            }\n            # Use last predictions/targets if no best saved\n            if best_PROBS is None and 'PROBS' in locals(): best_PROBS = PROBS\n            if best_TARGETS is None and 'TARGETS' in locals(): best_TARGETS = TARGETS\n            # Use last model state if no best saved\n            if best_model_state is None and 'model' in locals(): best_model_state = model.module.state_dict()\n            best_epoch_num = last_epoch_completed # Mark as last epoch\n        else:\n            print(\"WARNING: No validation results available to log.\")\n\n        final_metrics_to_log['total_training_time'] = total_time\n        final_metrics_to_log['last_epoch_completed'] = last_epoch_completed\n        final_metrics_to_log['best_epoch_logged'] = best_epoch_num # Clarify which epoch's metrics are logged\n\n\n        # Log final summary metrics to WandB\n        if wandb and wandb.run:\n             summary_log = {}\n             print(\"\\nFinal Metrics (logged to WandB Summary):\")\n             for k, v in sorted(final_metrics_to_log.items()):\n                 # Prepare for summary (only scalars/simple types)\n                 if isinstance(v, (int, float, bool, str)):\n                     summary_log[k] = v\n                 elif isinstance(v, np.ndarray) and v.size == 1:\n                     summary_log[k] = v.item()\n                 # Print logic\n                 if isinstance(v, (list, tuple, np.ndarray)) and len(v) > 10:\n                      print(f\"  - {k}: Type={type(v)}, Shape/Len={getattr(v, 'shape', len(v))} (Logged separately)\")\n                 elif isinstance(v, (float, np.float32, np.float64)):\n                      print(f\"  - {k}: {v:.6f}\")\n                 else:\n                      print(f\"  - {k}: {v}\")\n             wandb.summary.update(summary_log)\n\n\n        # Save and Log FINAL Best Model Artifact\n        if best_model_state is not None:\n            final_model_path = f'{kernel_type}_BEST_epoch{best_epoch_num}.pth'\n            torch.save({\n                'epoch': best_epoch_num,\n                'model_state_dict': best_model_state,\n                'best_composite_score': best_score,\n                'best_metrics': best_metrics # Save the detailed metrics dict\n             }, final_model_path)\n            print(f\"\\nSaved FINAL Best Model locally: {final_model_path}\")\n\n            if wandb and wandb.run:\n                model_artifact = wandb.Artifact(f\"model-{wandb.run.id}-BEST\", type=\"model\",\n                                                description=f\"Best model (Epoch {best_epoch_num}, Score: {best_score:.6f})\")\n                model_artifact.add_file(final_model_path)\n                wandb.log_artifact(model_artifact, aliases=[\"best\", f\"epoch_{best_epoch_num}\"])\n                print(\"Logged FINAL best model artifact to WandB.\")\n\n            # Save and Log FINAL Best Predictions Artifact\n            if best_PROBS is not None and best_TARGETS is not None and wandb and wandb.run:\n                try:\n                    if not isinstance(best_PROBS, np.ndarray): best_PROBS = np.array(best_PROBS)\n                    if not isinstance(best_TARGETS, np.ndarray): best_TARGETS = np.array(best_TARGETS)\n                    probs_filename = f\"best_probs_epoch_{best_epoch_num}.npy\"\n                    targets_filename = f\"best_targets_epoch_{best_epoch_num}.npy\"\n                    np.save(probs_filename, best_PROBS, allow_pickle=False)\n                    np.save(targets_filename, best_TARGETS, allow_pickle=False)\n                    print(f\"Saved best validation predictions/targets: {probs_filename}, {targets_filename}\")\n\n                    pred_artifact = wandb.Artifact(f\"val-predictions-{wandb.run.id}-BEST\", type=\"validation_predictions\",\n                                                  description=f\"Validation predictions/targets from best epoch {best_epoch_num}\")\n                    pred_artifact.add_file(probs_filename)\n                    pred_artifact.add_file(targets_filename)\n                    wandb.log_artifact(pred_artifact, aliases=[\"best_predictions\", f\"epoch_{best_epoch_num}\"])\n                    print(\"Logged best validation predictions/targets artifact to WandB.\")\n                    # os.remove(probs_filename) # Optional cleanup\n                    # os.remove(targets_filename)\n                except Exception as e:\n                    print(f\"Error saving/logging FINAL prediction artifacts: {e}\")\n        else:\n            print(\"\\nNo best model state recorded, skipping final model/prediction artifact saving.\")\n\n        # Log final CM tables from best_metrics\n        if best_metrics and wandb and wandb.run:\n             binary_cm_list = best_metrics.get('binary_conf_matrix', [[0,0],[0,0]])\n             multiclass_cm_list = best_metrics.get('multiclass_conf_matrix', [])\n             if out_dim == 9: class_names = ['AK','BCC','BKL','DF','SCC','VASC','melanoma','nevus','unknown']\n             else: class_names = [str(i) for i in range(out_dim)]\n\n             wandb.log({\n                 \"binary_confusion_matrix_table_BEST\": wandb.Table(columns=['Pred Non-Mel', 'Pred Mel'], data=binary_cm_list)\n             }, step=n_epochs) # Log at final step\n             if multiclass_cm_list:\n                 wandb.log({\n                     \"multiclass_confusion_matrix_table_BEST\": wandb.Table(columns=[f\"Pred {name}\" for name in class_names], data=multiclass_cm_list)\n                 }, step=n_epochs)\n\n\n    # --- Function Return (Matching previous simplified version) ---\n    print(\"--- Exiting run_single_model ---\")\n    return (model, best_model_state, final_metrics_to_log, train_losses, val_losses,\n            best_PROBS, best_TARGETS, # REMOVED best_STD_PROBS\n            df_valid_set, diagnosis2idx,\n            best_epoch_num, kernel_type, early_stopping,\n            model_type, enet_type, n_meta_features, image_size, out_dim,\n            lr_scale_factors, dropout_scale_factors\n           ) # Total 19 return values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main execution","metadata":{}},{"cell_type":"code","source":"import time\n\nif __name__ == \"__main__\":\n    print(f\"Training a single model with {kernel_type}...\")\n    start_time = time.time()\n    model_type='hybrid' # Or 'hybrid' depending on the run\n\n    # --- CORRECTED FUNCTION CALL (unpacking matches 19 return values) ---\n    (model, best_model_state, final_metrics, train_losses, val_losses,\n     best_PROBS, best_TARGETS, # Removed best_STD_PROBS from this list\n     df_valid_set, diagnosis2idx,\n     best_epoch_num, kernel_type, early_stopping,\n     model_type_ret, enet_type_ret, n_meta_features_ret, image_size_ret, out_dim_ret,\n     lr_scale_factors, dropout_scale_factors\n    ) = run_single_model(model_type=model_type, enet_type=enet_type)\n\n\n    total_time = time.time() - start_time\n    print(f\"Total training time: {total_time:.2f}s\")\n    print(\"Final Metrics:\", final_metrics)\n    if final_metrics:\n        print(f\"Binary AUC: {final_metrics.get('binary_auc', 0.0):.4f}\")\n        print(f\"Multiclass AUC: {final_metrics.get('multiclass_auc', 0.0):.4f}\")\n\n    # Now, when the Grad-CAM code runs after this block,\n    # df_valid_set and diagnosis2idx will exist in the global scope.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Section: Model Calibration Visualization (Reliability Diagram)","metadata":{}},{"cell_type":"code","source":"# This section visualizes the calibration of the best model's probabilities\n# for the primary class of interest (melanoma) using a reliability diagram.\n# It leverages the saved predictions and targets from the best validation epoch.\n# ==============================================================================\n\nimport matplotlib.pyplot as plt\nfrom sklearn.calibration import calibration_curve\nimport numpy as np\nimport wandb # Assuming wandb is potentially still active or needed for logging\n\nprint(\"\\n===== Starting Model Calibration Visualization =====\")\n\n# --- 1. Prerequisite Check ---\nrequired_vars_for_calibration = ['best_PROBS', 'best_TARGETS', 'mel_idx', 'best_epoch_num', 'kernel_type']\ncalibration_vars_ok = True\nfor var_name in required_vars_for_calibration:\n    if var_name not in locals() or locals()[var_name] is None:\n        print(f\"ERROR: Calibration requires '{var_name}', which is missing or None.\")\n        calibration_vars_ok = False\n    # Specifically check if the arrays are non-empty if they exist\n    elif var_name in ['best_PROBS', 'best_TARGETS'] and len(locals()[var_name]) == 0:\n        print(f\"ERROR: Calibration requires non-empty '{var_name}'. Found empty array.\")\n        calibration_vars_ok = False\n\nif not calibration_vars_ok:\n    print(\"Skipping calibration plot generation due to missing prerequisites.\")\nelse:\n    print(f\"Prerequisites met. Generating calibration plot for Melanoma class (index {mel_idx}) from Epoch {best_epoch_num}.\")\n\n    # --- 2. Prepare Data for Binary Calibration (Melanoma vs Non-Melanoma) ---\n    try:\n        # Ensure they are numpy arrays\n        if not isinstance(best_PROBS, np.ndarray): best_PROBS = np.array(best_PROBS)\n        if not isinstance(best_TARGETS, np.ndarray): best_TARGETS = np.array(best_TARGETS)\n\n        # Extract probabilities for the positive class (melanoma)\n        # Ensure mel_idx is within bounds\n        if mel_idx < 0 or mel_idx >= best_PROBS.shape[1]:\n             raise IndexError(f\"mel_idx ({mel_idx}) is out of bounds for best_PROBS shape {best_PROBS.shape}\")\n        y_prob_melanoma = best_PROBS[:, mel_idx]\n\n        # Create binary true labels (1 if melanoma, 0 otherwise)\n        y_true_binary = (best_TARGETS == mel_idx).astype(int)\n\n        # Check if there's variation in true labels (needed for calibration curve)\n        if len(np.unique(y_true_binary)) < 2:\n            print(\"WARNING: Only one class present in the best validation targets. Calibration curve may not be meaningful.\")\n            # Optionally skip plotting here if desired\n\n        print(f\"  Prepared data: y_prob_melanoma shape {y_prob_melanoma.shape}, y_true_binary shape {y_true_binary.shape}\")\n        print(f\"  Number of positive (melanoma) samples in best validation set: {np.sum(y_true_binary)}\")\n\n        # --- 3. Calculate Calibration Curve ---\n        # Use 'uniform' strategy for equally spaced bins based on probability.\n        # 'quantile' can also be used for bins with equal numbers of samples.\n        n_bins = 10 # A common choice, can be adjusted\n        prob_true, prob_pred = calibration_curve(y_true_binary, y_prob_melanoma, n_bins=n_bins, strategy='uniform')\n\n        print(f\"  Calculated calibration curve points (True Probability, Predicted Probability):\")\n        for pt, pp in zip(prob_true, prob_pred):\n            print(f\"    {pt:.4f}, {pp:.4f}\")\n\n        # --- 4. Plot Reliability Diagram ---\n        plt.figure(figsize=(8, 8))\n        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n        plt.plot(prob_pred, prob_true, marker='s', linestyle='-', label='Model Calibration (Melanoma Class)')\n\n        plt.xlabel(\"Mean Predicted Probability (in bin)\", fontsize=12)\n        plt.ylabel(\"Fraction of Positives (in bin)\", fontsize=12)\n        plt.title(f\"Calibration Plot (Reliability Diagram) - Epoch {best_epoch_num}\\n{kernel_type}\", fontsize=14, pad=15)\n        plt.legend(loc='lower right', fontsize=10)\n        plt.grid(True, linestyle=':', alpha=0.6)\n        plt.tight_layout()\n\n        # --- 5. Save and Log Plot ---\n        calibration_plot_filename = f\"{kernel_type}_calibration_plot_epoch{best_epoch_num}.png\"\n        plt.savefig(calibration_plot_filename, dpi=150)\n        print(f\"  Saved calibration plot locally: {calibration_plot_filename}\")\n        plt.show() # Display the plot in the notebook\n\n        # Log to WandB if available and run is active\n        if 'wandb' in locals() and wandb is not None and wandb.run is not None:\n            try:\n                wandb.log({\"calibration_plot_melanoma\": wandb.Image(calibration_plot_filename)}, step=best_epoch_num) # Log at the best epoch step\n                print(\"  Logged calibration plot to WandB.\")\n            except Exception as e:\n                print(f\"  Warning: Failed to log calibration plot to WandB: {e}\")\n        else:\n            print(\"  Skipping WandB logging for calibration plot (WandB not active).\")\n\n    except Exception as e:\n        print(f\"\\nERROR generating calibration plot: {e}\")\n        import traceback\n        traceback.print_exc()\n\nprint(\"===== Model Calibration Visualization Finished =====\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.finish()  # End the W&B run","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-Cam Run","metadata":{}},{"cell_type":"code","source":"print(\"--- Debug Check Before Grad-CAM ---\")\nrequired_vars_check = [\n    'df_valid_set', 'diagnosis2idx', 'best_model_state', 'model_type',\n    'enet_type', 'n_meta_features', 'image_size', 'out_dim',\n    'mel_idx', 'kernel_type', 'best_epoch_num', 'dropout_scale_factors',\n    'early_stopping', 'lr_scale_factors' # Add any others you suspect\n]\nvariables_exist = {}\nfor var_name in required_vars_check:\n    variables_exist[var_name] = var_name in locals()\n    if variables_exist[var_name]:\n        # Optionally print type or shape for complex variables\n        if isinstance(locals()[var_name], (pd.DataFrame, np.ndarray, torch.Tensor)):\n             print(f\"Variable '{var_name}': Exists, Type: {type(locals()[var_name])}, Shape: {locals()[var_name].shape}\")\n        elif isinstance(locals()[var_name], dict):\n             print(f\"Variable '{var_name}': Exists, Type: {type(locals()[var_name])}, Keys (first 5): {list(locals()[var_name].keys())[:5]}\")\n        else:\n             print(f\"Variable '{var_name}': Exists, Type: {type(locals()[var_name])}, Value: {locals()[var_name]}\")\n\n    else:\n        print(f\"Variable '{var_name}': DOES NOT EXIST\")\n\nprint(\"--- End Debug Check ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Add this line to reset the index ---\ndf_valid_set = df_valid_set.reset_index(drop=True)\nprint(\"Reset index of df_valid_set to ensure uniqueness for visualization sampling.\")\n# --- End Add ---\nprint(\"\\n===== Starting Grad-CAM Visualization (True vs. Predicted Focus) =====\")\n\n# --- Configuration ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_images_to_visualize = 10 # Show 10 images\n\n# --- Explicit Prerequisite Check ---\nprint(\"\\n--- Explicit Variable Check ---\")\nrequired_vars = ['df_valid_set', 'diagnosis2idx', 'best_model_state', 'model_type',\n                 'enet_type', 'n_meta_features', 'image_size', 'out_dim',\n                 'mel_idx', 'kernel_type', 'best_epoch_num', 'dropout_scale_factors',\n                 'early_stopping', 'lr_scale_factors'] # Make sure all returned vars are checked\n\nall_vars_ok = True\nfor var_name in required_vars:\n    if var_name not in locals():\n        print(f\"ERROR: Variable '{var_name}' NOT FOUND in locals().\")\n        all_vars_ok = False\n    elif locals()[var_name] is None:\n        # Special check for pandas DataFrame which can be tricky with 'is None'\n        if isinstance(locals()[var_name], pd.DataFrame) and locals()[var_name].empty:\n             print(f\"INFO: Variable '{var_name}' is an EMPTY DataFrame, but exists.\")\n             # Decide if an empty DataFrame is acceptable here - probably ok for df_valid_set if training failed instantly\n        else:\n             print(f\"ERROR: Variable '{var_name}' FOUND but is None.\")\n             all_vars_ok = False\n    else:\n        # Optional: Confirm variables are okay\n        # print(f\"OK: Variable '{var_name}' exists and is not None.\")\n        pass\n\nif not all_vars_ok:\n    print(\"Error: One or more prerequisite variables are missing or None.\")\n    print(\"Ensure training completed successfully and returned all required variables.\")\n    print(\"--- End Explicit Variable Check ---\")\n    # Stop execution here if check fails (or rely on else block not running)\n\nelse: # <<< Correct Main Else Block >>>\n    print(\"All prerequisite variables seem OK. Proceeding...\")\n    print(\"--- End Explicit Variable Check ---\")\n    print(f\"Visualizing model type: '{model_type}', enet_type: '{enet_type}', using metadata: {n_meta_features > 0}\")\n\n    # --- Instantiate the *Trained* Model Architecture ---\n    print(\"\\nInstantiating the trained model architecture...\")\n    if model_type == 'hybrid':\n        viz_model = HybridModel(\n            backbone=enet_type, out_dim=out_dim, n_meta_features=n_meta_features,\n            image_size=image_size, load_pretrained=False,\n            dropout_scale_factors=dropout_scale_factors\n        ).to(device)\n        print(\"  Instantiated HybridModel\")\n    elif model_type == 'efficientnet':\n         viz_model = enetv2(\n            enet_type, out_dim=out_dim, n_meta_features=n_meta_features,\n            load_pretrained=False, dropout_scale_factors=dropout_scale_factors\n        ).to(device)\n         print(\"  Instantiated enetv2\")\n    else:\n        print(f\"Error: Unknown model_type '{model_type}' for visualization.\")\n        viz_model = None\n\n    if viz_model:\n        # --- Load Best State Dict ---\n        print(\"\\nLoading best model state...\")\n        has_module_prefix_in_state = any(k.startswith('module.') for k in best_model_state.keys())\n        if not has_module_prefix_in_state:\n            print(\"  Adding 'module.' prefix to saved state dict keys for DataParallel loading.\")\n            state_dict_to_load = {'module.' + k: v for k, v in best_model_state.items()}\n        else:\n             state_dict_to_load = best_model_state\n\n        viz_model = torch.nn.DataParallel(viz_model) # Wrap in DataParallel\n        print(f\"  Wrapping model in DataParallel.\")\n\n        try:\n            load_result = viz_model.load_state_dict(state_dict_to_load, strict=True)\n            print(f\"  Successfully loaded best model state (strict=True).\")\n        except RuntimeError as e:\n            print(f\"  Warning: Strict loading failed ({e}). Trying with strict=False...\")\n            try:\n                 load_result = viz_model.load_state_dict(state_dict_to_load, strict=False)\n                 print(f\"  Successfully loaded best model state (strict=False).\")\n                 print(f\"    Load Result (strict=False) - Missing keys: {len(load_result.missing_keys)}, Unexpected keys: {len(load_result.unexpected_keys)}\")\n                 if load_result.missing_keys: print(f\"      Missing: {load_result.missing_keys[:5]}...\")\n                 if load_result.unexpected_keys: print(f\"      Unexpected: {load_result.unexpected_keys[:5]}...\")\n            except Exception as E:\n                 print(f\"  ERROR: Failed to load model state even with strict=False: {E}\")\n                 viz_model = None\n\n        # --- Identify Target Layer ---\n        if viz_model:\n            print(\"\\nIdentifying target layer...\")\n            target_layer = None\n            try:\n                if hasattr(viz_model.module, 'enet') and hasattr(viz_model.module.enet, 'conv_head'):\n                     target_layer = viz_model.module.enet.conv_head\n                     print(f\"  Identified target layer: viz_model.module.enet.conv_head\")\n                elif hasattr(viz_model.module, 'enet') and hasattr(viz_model.module.enet, 'blocks'):\n                         target_layer = viz_model.module.enet.blocks[-1]\n                         print(f\"  Using fallback target layer: viz_model.module.enet.blocks[-1]\")\n                else: print(\"  Error: Cannot determine target layer.\")\n            except AttributeError: print(\"  Error accessing model layers.\")\n\n            if target_layer:\n                viz_model.eval()\n\n                                # --- Seed for Reproducible Image Selection ---\n                SEED_FOR_VISUALIZATION = 42 # You can choose any integer here, just keep it constant\n                rng = np.random.default_rng(seed=SEED_FOR_VISUALIZATION)\n                print(f\"Using fixed random seed {SEED_FOR_VISUALIZATION} for image selection.\")\n                # --- End Seed ---\n\n                # --- Select Images Randomly (but reproducibly) ---\n                num_available = len(df_valid_set)\n                num_to_sample = min(num_images_to_visualize, num_available)\n                if num_to_sample > 0:\n                    # Use the seeded random number generator (rng)\n                    random_image_indices = rng.choice(num_available, num_to_sample, replace=False).tolist()\n                    # Sort the indices for consistency in the order they are processed (optional but good practice)\n                    random_image_indices.sort()\n                    print(f\"\\nSelected {len(random_image_indices)} reproducible image indices for visualization: {random_image_indices}\")\n                else:\n                    print(\"Warning: No images available in df_valid_set to sample.\")\n                    random_image_indices = []\n                # --- End Image Selection ---\n\n                # --- Generate Grad-CAMs ---\n                print(\"\\nGenerating Grad-CAMs...\")\n                for img_index in random_image_indices:\n                    try:\n                        image_info = df_valid_set.loc[img_index]\n                        image_path = image_info['filepath']\n\n                        # Robust label extraction\n                        true_label_idx_val = image_info['target']\n                        if isinstance(true_label_idx_val, pd.Series): true_label_idx = int(true_label_idx_val.iloc[0])\n                        elif isinstance(true_label_idx_val, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64)): true_label_idx = int(true_label_idx_val)\n                        elif isinstance(true_label_idx_val, (int, float)): true_label_idx = int(true_label_idx_val)\n                        else: raise TypeError(f\"Unexpected type for target: {type(true_label_idx_val)}\")\n                        try: true_label_name = list(diagnosis2idx.keys())[list(diagnosis2idx.values()).index(true_label_idx)]\n                        except ValueError: true_label_name = f\"Unknown ({true_label_idx})\"\n\n                        print(f\"\\nProcessing Image: {os.path.basename(image_path)} (Index: {img_index}, True Label: {true_label_name} [{true_label_idx}])\")\n\n                        # Load and preprocess image\n                        input_tensor, img_for_display = load_and_preprocess_for_gradcam(image_path, image_size)\n                        input_tensor = input_tensor.to(device)\n\n                        # Prepare metadata tensor\n                        meta_tensor_for_image = None\n                        model_uses_meta = n_meta_features > 0\n                        if model_uses_meta:\n                            if 'meta_features' in locals():\n                                meta_values = image_info[meta_features].values.astype(np.float32)\n                                meta_tensor_for_image = torch.tensor(meta_values).unsqueeze(0).to(device)\n                            else: print(\"  Warning: Metadata expected but 'meta_features' list not found.\")\n\n                        # Get Model Prediction\n                        pred_label_name = \"N/A\"; pred_label_idx = -1; pred_prob_for_true_class = 0.0; pred_prob_for_pred_class = 0.0\n                        with torch.no_grad():\n                            logits = None\n                            if model_uses_meta and meta_tensor_for_image is not None: logits = viz_model(input_tensor, meta_tensor_for_image)\n                            elif model_uses_meta and meta_tensor_for_image is None: print(\"  Skipping prediction: Metadata needed but not available.\"); pred_label_name = \"Error (Meta Missing)\"\n                            else: logits = viz_model(input_tensor) # No meta needed\n\n                            if logits is not None:\n                                pred_prob = torch.softmax(logits, dim=1)\n                                pred_label_idx = torch.argmax(pred_prob, dim=1).item()\n                                pred_prob_for_pred_class = pred_prob[0, pred_label_idx].item()\n                                try: pred_label_name = list(diagnosis2idx.keys())[list(diagnosis2idx.values()).index(pred_label_idx)]\n                                except ValueError: pred_label_name = f\"Unknown ({pred_label_idx})\"\n                                if 0 <= true_label_idx < pred_prob.shape[1]: pred_prob_for_true_class = pred_prob[0, true_label_idx].item()\n                                else: pred_prob_for_true_class = -1.0\n                            # (Error handling for prediction stays)\n\n                        print(f\"  Prediction: {pred_label_name} [{pred_label_idx}] (Prob: {pred_prob_for_pred_class:.3f})\")\n\n                        # Generate CAM for TRUE Class\n                        print(f\"  Generating CAM for TRUE Class: {true_label_name} [{true_label_idx}]\")\n                        visualization_true, _ = generate_gradcam(\n                            model=viz_model, target_layer=target_layer, input_tensor=input_tensor,\n                            original_image=img_for_display, target_class_idx=true_label_idx,\n                            device=device, meta_tensor=meta_tensor_for_image\n                        )\n\n                        # Generate CAM for PREDICTED Class\n                        visualization_pred = None\n                        if pred_label_idx != -1 and pred_label_idx != true_label_idx :\n                            print(f\"  Generating CAM for PREDICTED Class: {pred_label_name} [{pred_label_idx}]\")\n                            visualization_pred, _ = generate_gradcam(\n                                model=viz_model, target_layer=target_layer, input_tensor=input_tensor,\n                                original_image=img_for_display, target_class_idx=pred_label_idx,\n                                device=device, meta_tensor=meta_tensor_for_image\n                            )\n                        elif pred_label_idx == true_label_idx:\n                             print(f\"  Skipping CAM for predicted class (same as true class).\")\n                             visualization_pred = visualization_true # Reuse CAM if pred == true\n                        else:\n                            print(\"  Skipping CAM for predicted class due to prediction error.\")\n\n                        # Display Results\n                        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n                        axes[0].imshow(img_for_display)\n                        axes[0].set_title(f\"Original\\nTrue: {true_label_name} [{true_label_idx}]\")\n                        axes[0].axis('off')\n                        axes[1].imshow(visualization_true)\n                        axes[1].set_title(f\"CAM for True ({true_label_name})\\nModel's Prob: {pred_prob_for_true_class:.3f}\")\n                        axes[1].axis('off')\n                        if visualization_pred is not None:\n                            axes[2].imshow(visualization_pred)\n                            axes[2].set_title(f\"CAM for Pred ({pred_label_name})\\nModel's Prob: {pred_prob_for_pred_class:.3f}\")\n                        else:\n                             if pred_label_idx == -1: info_text = 'Prediction Error\\nNo CAM Generated'\n                             elif pred_label_idx == true_label_idx: info_text = 'Prediction = True\\n(CAM same as True)'\n                             else: info_text = 'CAM Pred Error'\n                             axes[2].text(0.5, 0.5, info_text, ha='center', va='center', fontsize=10)\n                             axes[2].set_title(f\"CAM for Pred ({pred_label_name})\")\n                        axes[2].axis('off')\n                        plt.suptitle(f\"Image: {os.path.basename(image_path)} (Idx: {img_index}) | Model: {model_type}/{enet_type}\", fontsize=14)\n                        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n                        plt.show()\n\n                    except Exception as e:\n                        print(f\"  Failed significantly on image {img_index}: {e}\")\n                        import traceback\n                        traceback.print_exc()\n\n            else:\n                print(\"Skipping CAM generation as target layer couldn't be identified.\")\n        else:\n             print(\"Skipping CAM generation as model loading or state dict loading failed.\")\n\n# This final print is outside the main 'else' corresponding to 'if all_vars_ok:'\nprint(\"\\n===== Grad-CAM Visualization Finished =====\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}